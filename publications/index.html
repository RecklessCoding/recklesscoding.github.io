<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Publications | Αndreas Theodorou </title> <meta name="author" content="Andreas Theodorou"> <meta name="description" content="Publications in reversed chronological order and by categories. Drafts available upon request. My research spans upon categories related to Responsible AI: AI Governance, AI Safety, human control, transparency, and XAI. In addition, I have published in topics such as agents, cognitive architectures, games AI, and multi-agent systems."> <meta name="keywords" content="artificial intelligence, AI ethics, AI governance, responsible AI, AI, LLMs, reactive planning, control"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?v=a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%A4%96&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://recklesscoding.github.io/publications/"> <script src="/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Αndreas Theodorou </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item active"> <a class="nav-link" href="/publications/">Publications <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/people/">Students </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">Teaching </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Publications</h1> <p class="post-description">Publications in reversed chronological order and by categories. Drafts available upon request. My research spans upon categories related to Responsible AI: AI Governance, AI Safety, human control, transparency, and XAI. In addition, I have published in topics such as agents, cognitive architectures, games AI, and multi-agent systems.</p> </header> <article> <div class="publications"> <h2 class="bibliography">2026</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#af0000"> <div style="color:white">Journal</div> </abbr> <keyword class="badge rounded w-100" style="background-color:#851868"> <div style="color:white">Governance</div> </keyword> <keyword class="badge rounded w-100" style="background-color:#355E3B"> <div style="color:white">Human Control</div> </keyword> </div> <div id="mckinlay2026" class="col-sm-8"> <div class="title">Understanding the Process of Human-AI Value Alignment</div> <div class="author"> Jack McKinlay, Marina De Vos, Janina A. Hoffmann, and <em>Andreas Theodorou</em> </div> <div class="periodical"> <em>Accepted in: Journal of Artificial Intelligence Research (coming in 2026)</em>, 2026 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2509.13854" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> </div> <div class="badges"> <span> <a href="https://plu.mx/plum/a/?doi=" data-popup="right" data-size="small" class="plumx-plum-print-popup" data-site="plum" data-hide-when-empty="true" rel="external nofollow noopener" target="_blank"> </a> </span> </div> <div class="abstract hidden"> <p>Value alignment in computer science research is often used to refer to the process of aligning artificial intelligence with humans, but the way the phrase is used often lacks precision. In this paper, we conduct a systematic literature review to advance the understanding of value alignment in artificial intelligence by characterising the topic in the context of its research literature. We use this to suggest a more precise definition of the term. We analyse 172 value alignment research articles that have been published in recent years and synthesise their content using thematic analyses. Our analysis leads to six themes: value alignment drivers &amp; approaches; challenges in value alignment; values in value alignment; cognitive processes in humans and AI; human-agent teaming; and designing and developing value-aligned systems. Conclusions: By analysing these themes in the context of the literature we define value alignment as an ongoing process between humans and autonomous agents that aims to express and implement abstract values in diverse contexts, while managing the cognitive limits of both humans and AI agents and also balancing the conflicting ethical and political demands generated by the values in different groups. Our analysis gives rise to a set of research challenges and opportunities in the field of value alignment for future work.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2025</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ff7802"> <div style="color:white">Proceedings</div> </abbr> <keyword class="badge rounded w-100" style="background-color:#851868"> <div style="color:white">Governance</div> </keyword> <keyword class="badge rounded w-100" style="background-color:#154e54"> <div style="color:white">Contestability</div> </keyword> </div> <div id="DignumEtAl2025AAMAS" class="col-sm-8"> <div class="title">Contesting Black-Box AI Decisions</div> <div class="author"> Virginia Dignum, Loizos Michael, Juan Carlos Nieves, Marija Slavkovik, Julliett Suarez, and <em>Andreas Theodorou</em> </div> <div class="periodical"> <em>In 24th Int. Conf. on Autonomous Agents and Multiagent Systems (AAMAS)</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.65109/RWZD3386" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> <span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=JEw-BycAAAAJ&amp;citation_for_view=JEw-BycAAAAJ:ZHo1McVdvXMC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-5-4285F4?logo=googlescholar&amp;labelColor=beige" alt="5 Google Scholar citations"> </a> </span> <span class="__dimensions_badge_embed__" data-doi="10.65109/RWZD3386" data-style="small_rectangle" data-legend="hover-right" data-hide-zero-citations="true" style="margin-bottom: 2px;"></span> <span class="altmetric-embed" data-badge-type="2" data-badge-popover="right" data-hide-no-mentions="true" data-doi="10.65109/RWZD3386" style="padding-right:0rem"></span> <span> <a href="https://plu.mx/plum/a/?doi=10.65109/RWZD3386" data-popup="right" data-size="small" class="plumx-plum-print-popup" data-site="plum" data-hide-when-empty="true" rel="external nofollow noopener" target="_blank"> </a> </span> </div> <div class="abstract hidden"> <p>The ”right to contest” decisions that have consequences on individuals or the society is a well-established democratic right. Contesting a decision is not a matter of simply providing an explanation, but rather of assessing whether the decision and the explanation are permissible against an organization’s governance framework. Yet, albeit the popularity of adjacent fields, little work has been explicitly done on contesting AI decisions. In this paper, we propose that formal argumentation can be used to formulate contestations of decisions made by artificial agents. We extend the discourse on socio-ethical values in AI by conceptualizing our argumentation framework as a formal dialogue, enabling the interaction between humans and agents as decisions are being contested.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">DignumEtAl2025AAMAS</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Dignum, Virginia and Michael, Loizos and Nieves, Juan Carlos and Slavkovik, Marija and Suarez, Julliett and Theodorou, Andreas}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Contesting Black-Box AI Decisions}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{24th Int. Conf. on Autonomous Agents and Multiagent Systems (AAMAS)}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.65109/RWZD3386}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#7c4242"> <div style="color:white">Book Chapter</div> </abbr> <keyword class="badge rounded w-100" style="background-color:#851868"> <div style="color:white">Governance</div> </keyword> <keyword class="badge rounded w-100" style="background-color:#FFDA03"> <div style="color:white">Safety</div> </keyword> </div> <div id="Bakirtzis2025DynamicCert" class="col-sm-8"> <div class="title">Navigating the sociotechnical labyrinth: dynamic certification for responsible embodied AI</div> <div class="author"> Georgios Bakirtzis, Andrea Aler Tubella, <em>Andreas Theodorou</em>, David Danks, and Ufuk Topcu </div> <div class="periodical"> <em>In Bi-directionality in Human-AI Collaborative Systems</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1016/B978-0-44-340553-2.00019-8" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> <span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=JEw-BycAAAAJ&amp;citation_for_view=JEw-BycAAAAJ:M05iB0D1s5AC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-4-4285F4?logo=googlescholar&amp;labelColor=beige" alt="4 Google Scholar citations"> </a> </span> <span class="__dimensions_badge_embed__" data-doi="10.1016/B978-0-44-340553-2.00019-8" data-style="small_rectangle" data-legend="hover-right" data-hide-zero-citations="true" style="margin-bottom: 2px;"></span> <span class="altmetric-embed" data-badge-type="2" data-badge-popover="right" data-hide-no-mentions="true" data-altmetric-id="124257548" style="padding-right:0rem"></span> <span> <a href="https://plu.mx/plum/a/?doi=10.1016/B978-0-44-340553-2.00019-8" data-popup="right" data-size="small" class="plumx-plum-print-popup" data-site="plum" data-hide-when-empty="true" rel="external nofollow noopener" target="_blank"> </a> </span> </div> <div class="abstract hidden"> <p>Sociotechnical requirements shape the governance of artificially intelligent (AI) systems. In an era where embodied AI technologies are rapidly reshaping various facets of contemporary society, their inherent dynamic adaptability presents a unique blend of opportunities and challenges. Traditional regulatory mechanisms, often designed for static—or slower-paced—technologies, find themselves at a crossroads when faced with the fluid and evolving nature of AI systems. Moreover, typical problems in AI, for example, the frequent opacity and unpredictability of the behavior of the systems, add additional sociotechnical challenges. To address these interconnected issues, we introduce the concept of dynamic certification, an adaptive regulatory framework specifically crafted to keep pace with the continuous evolution of AI systems. The complexity of these challenges requires common progress in multiple domains: technical, socio-governmental, and regulatory. Our proposed transdisciplinary approach is designed to ensure the safe, ethical, and practical deployment of AI systems, aligning them bidirectionally with the real-world contexts in which they operate. By doing so, we aim to bridge the gap between rapid technological advancement and effective regulatory oversight, ensuring that AI systems not only achieve their intended goals but also adhere to ethical standards and societal values.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@incollection</span><span class="p">{</span><span class="nl">Bakirtzis2025DynamicCert</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Bakirtzis, Georgios and {Aler Tubella}, Andrea and Theodorou, Andreas and Danks, David and Topcu, Ufuk}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Navigating the sociotechnical labyrinth: dynamic certification for responsible embodied AI}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Bi-directionality in Human-AI Collaborative Systems}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Academic Press}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1016/B978-0-44-340553-2.00019-8}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#af0000"> <div style="color:white">Journal</div> </abbr> <keyword class="badge rounded w-100" style="background-color:#154e54"> <div style="color:white">XAI</div> </keyword> <keyword class="badge rounded w-100" style="background-color:#4169E1"> <div style="color:white">MLOPs</div> </keyword> </div> <div id="FaubelEtAl2025MLOps" class="col-sm-8"> <div class="title">MLOps for Cyberphysical Production Systems: Challenges and Solutions</div> <div class="author"> Leonhard Faubel, Thomas Woudsma, Benjamin Kloepper, Holger Eichelberger, Fabian Buelow, Klaus Schmid, and <span class="more-authors" title="click to view 4 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '4 more authors' ? 'Amir Ghorbani Ghezeljehmeidan, Leila Methnani, Andreas Theodorou, Magnus Bång' : '4 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">4 more authors</span> </div> <div class="periodical"> <em>IEEE Software</em>, 2025 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1109/MS.2024.3441101" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> <span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=JEw-BycAAAAJ&amp;citation_for_view=JEw-BycAAAAJ:ldfaerwXgEUC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-4-4285F4?logo=googlescholar&amp;labelColor=beige" alt="4 Google Scholar citations"> </a> </span> <span class="__dimensions_badge_embed__" data-doi="10.1109/MS.2024.3441101" data-style="small_rectangle" data-legend="hover-right" data-hide-zero-citations="true" style="margin-bottom: 2px;"></span> <span class="altmetric-embed" data-badge-type="2" data-badge-popover="right" data-hide-no-mentions="true" data-doi="10.1109/MS.2024.3441101" style="padding-right:0rem"></span> <span> <a href="https://plu.mx/plum/a/?doi=10.1109/MS.2024.3441101" data-popup="right" data-size="small" class="plumx-plum-print-popup" data-site="plum" data-hide-when-empty="true" rel="external nofollow noopener" target="_blank"> </a> </span> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">FaubelEtAl2025MLOps</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Faubel, Leonhard and Woudsma, Thomas and Kloepper, Benjamin and Eichelberger, Holger and Buelow, Fabian and Schmid, Klaus and Ghezeljehmeidan, Amir Ghorbani and Methnani, Leila and Theodorou, Andreas and Bång, Magnus}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Software}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{MLOps for Cyberphysical Production Systems: Challenges and Solutions}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2025}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{42}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{65-73}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/MS.2024.3441101}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ff7802"> <div style="color:white">Proceedings</div> </abbr> <keyword class="badge rounded w-100" style="background-color:#80461B"> <div style="color:white">Cogn. Arch.</div> </keyword> <keyword class="badge rounded w-100" style="background-color:#355E3B"> <div style="color:white">Human Control</div> </keyword> </div> <div id="Bakirtzis2024NegotiatingCN" class="col-sm-8"> <div class="title">Negotiating Control: Neurosymbolic Variable Autonomy</div> <div class="author"> Georgios Bakirtzis, Manolis Chiou, and <em>Andreas Theodorou</em> </div> <div class="periodical"> <em>In Artificial Intelligence Research and Development - Proceedings of the 26th International Conference of the Catalan Association for Artificial Intelligence</em>, 2024 </div> <div class="periodical"> 26th International Conference of the Catalan Association for Artificial Intelligence, CCIA 2024 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.3233/FAIA240432" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> <span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=JEw-BycAAAAJ&amp;citation_for_view=JEw-BycAAAAJ:2P1L_qKh6hAC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-2-4285F4?logo=googlescholar&amp;labelColor=beige" alt="2 Google Scholar citations"> </a> </span> <span class="__dimensions_badge_embed__" data-doi="10.3233/FAIA240432" data-style="small_rectangle" data-legend="hover-right" data-hide-zero-citations="true" style="margin-bottom: 2px;"></span> <span class="altmetric-embed" data-badge-type="2" data-badge-popover="right" data-hide-no-mentions="true" data-doi="10.3233/FAIA240432" style="padding-right:0rem"></span> <span> <a href="https://plu.mx/plum/a/?doi=10.3233/FAIA240432" data-popup="right" data-size="small" class="plumx-plum-print-popup" data-site="plum" data-hide-when-empty="true" rel="external nofollow noopener" target="_blank"> </a> </span> </div> <div class="abstract hidden"> <p>Variable autonomy equips a system, such as a robot, with mixed initiatives such that it can adjust its independence level based on the task’s complexity and the surrounding environment. Variable autonomy solves two main problems in robotic planning: the first is the problem of humans being unable to keep focus in monitoring and intervening during robotic tasks without appropriate human factor indicators, and the second is achieving mission success in unpredictable and uncertain environments in the face of static reward structures. An open problem in variable autonomy is developing robust methods to dynamically balance autonomy and human intervention in real-time, ensuring optimal performance and safety in unpredictable and evolving environments. We posit that addressing unpredictable and evolving environments through an addition of rule-based symbolic logic has the potential to make autonomy adjustments more contextually reliable and adding feedback to reinforcement learning through data from mixed-initiative control further increases efficacy and safety of autonomous behavior.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Bakirtzis2024NegotiatingCN</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Negotiating Control: Neurosymbolic Variable Autonomy}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Bakirtzis, Georgios and Chiou, Manolis and Theodorou, Andreas}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{26th International Conference of the Catalan Association for Artificial Intelligence, CCIA 2024}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.3233/FAIA240432}</span><span class="p">,</span>
  <span class="na">language</span> <span class="p">=</span> <span class="s">{English}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Frontiers in Artificial Intelligence and Applications}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IOS Press BV}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{178-181}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Alsinet, Teresa and Vilasis--Cardona, Xavier and Garcia-Costa, Daniel and Alvarez-Garcia, Elena}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Artificial Intelligence Research and Development - Proceedings of the 26th International Conference of the Catalan Association for Artificial Intelligence}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#af0000"> <div style="color:white">Journal</div> </abbr> <keyword class="badge rounded w-100" style="background-color:#355E3B"> <div style="color:white">Human Control</div> </keyword> <keyword class="badge rounded w-100" style="background-color:#154e54"> <div style="color:white">Transparency</div> </keyword> </div> <div id="MethnaniEtAl2024WhoIsInChargeVASurvey" class="col-sm-8"> <div class="title">Who’s in Charge Here? A Survey on Trustworthy AI in Variable Autonomy Robotic Systems</div> <div class="author"> Leila Methnani, Manolis Chiou, Virginia Dignum, and <em>Andreas Theodorou</em> </div> <div class="periodical"> <em>ACM Computing Surveys</em>, Apr 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3645090" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://doi.org/10.1145/3645090" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> <div class="badges"> <span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=JEw-BycAAAAJ&amp;citation_for_view=JEw-BycAAAAJ:lSLTfruPkqcC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-31-4285F4?logo=googlescholar&amp;labelColor=beige" alt="31 Google Scholar citations"> </a> </span> <span class="__dimensions_badge_embed__" data-doi="10.1145/3645090" data-style="small_rectangle" data-legend="hover-right" data-hide-zero-citations="true" style="margin-bottom: 2px;"></span> <span class="altmetric-embed" data-badge-type="2" data-badge-popover="right" data-hide-no-mentions="true" data-doi="10.1145/3645090" style="padding-right:0rem"></span> <span> <a href="https://plu.mx/plum/a/?doi=10.1145/3645090" data-popup="right" data-size="small" class="plumx-plum-print-popup" data-site="plum" data-hide-when-empty="true" rel="external nofollow noopener" target="_blank"> </a> </span> </div> <div class="abstract hidden"> <p>This article surveys the Variable Autonomy (VA) robotics literature that considers two contributory elements to Trustworthy AI: transparency and explainability. These elements should play a crucial role when designing and adopting robotic systems, especially in VA where poor or untimely adjustments of the system’s level of autonomy can lead to errors, control conflicts, user frustration, and ultimate disuse of the system. Despite this need, transparency and explainability is, to the best of our knowledge, mostly overlooked in VA robotics literature or is not considered explicitly. In this article, we aim to present and examine the most recent contributions to the VA literature concerning transparency and explainability. In addition, we propose a way of thinking about VA by breaking these two concepts down based on: the mission of the human-robot team; who the stakeholder is; what needs to be made transparent or explained; why they need it; and how it can be achieved. Last, we provide insights and propose ways to move VA research forward. Our goal with this article is to raise awareness and inter-community discussions among the Trustworthy AI and the VA robotics communities.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">MethnaniEtAl2024WhoIsInChargeVASurvey</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Methnani, Leila and Chiou, Manolis and Dignum, Virginia and Theodorou, Andreas}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Who's in Charge Here? A Survey on Trustworthy AI in Variable Autonomy Robotic Systems}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">issue_date</span> <span class="p">=</span> <span class="s">{July 2024}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computing Machinery}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, USA}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{56}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{7}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{0360-0300}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1145/3645090}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3645090}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{ACM Computing Surveys}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">apr</span><span class="p">,</span>
  <span class="na">articleno</span> <span class="p">=</span> <span class="s">{184}</span><span class="p">,</span>
  <span class="na">numpages</span> <span class="p">=</span> <span class="s">{32}</span><span class="p">,</span>
  <span class="na">keyword</span> <span class="p">=</span> <span class="s">{Human Control}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ff7802"> <div style="color:white">Proceedings</div> </abbr> <keyword class="badge rounded w-100" style="background-color:#851868"> <div style="color:white">H-AI Int.</div> </keyword> <keyword class="badge rounded w-100" style="background-color:#154e54"> <div style="color:white">XAI</div> </keyword> </div> <div id="MethnaniEtAl2024ClashOfExplainers" class="col-sm-8"> <div class="title">Clash of the explainers : argumentation for context-appropriate explanations</div> <div class="author"> Leila Methnani, Virginia Dignum, and <em>Andreas Theodorou</em> </div> <div class="periodical"> <em>In Artificial Intelligence. ECAI 2023 : XAI^3, TACTIFUL, XI-ML, SEDAMI, RAAIT, AI4S, HYDRA, AI4AI, Kraków, Poland, September 30 - October 4, 2023, Proceedings, Part I</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1007/978-3-031-50396-2_1" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> <span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=JEw-BycAAAAJ&amp;citation_for_view=JEw-BycAAAAJ:RYcK_YlVTxYC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-1-4285F4?logo=googlescholar&amp;labelColor=beige" alt="1 Google Scholar citations"> </a> </span> <span class="__dimensions_badge_embed__" data-doi="10.1007/978-3-031-50396-2_1" data-style="small_rectangle" data-legend="hover-right" data-hide-zero-citations="true" style="margin-bottom: 2px;"></span> <span class="altmetric-embed" data-badge-type="2" data-badge-popover="right" data-hide-no-mentions="true" data-doi="10.1007/978-3-031-50396-2_1" style="padding-right:0rem"></span> <span> <a href="https://plu.mx/plum/a/?doi=10.1007/978-3-031-50396-2_1" data-popup="right" data-size="small" class="plumx-plum-print-popup" data-site="plum" data-hide-when-empty="true" rel="external nofollow noopener" target="_blank"> </a> </span> </div> <div class="abstract hidden"> <p>Understanding when and why to apply any given eXplainable Artificial Intelligence (XAI) technique is not a straightforward task. There is no single approach that is best suited for a given context. This paper aims to address the challenge of selecting the most appropriate explainer given the context in which an explanation is required. For AI explainability to be effective, explanations and how they are presented needs to be oriented towards the stakeholder receiving the explanation. If—in general—no single explanation technique surpasses the rest, then reasoning over the available methods is required in order to select one that is context-appropriate. Due to the transparency they afford, we propose employing argumentation techniques to reach an agreement over the most suitable explainers from a given set of possible explainers. In this paper, we propose a modular reasoning system consisting of a given mental model of the relevant stakeholder, a reasoner component that solves the argumentation problem generated by a multi-explainer component, and an AI model that is to be explained suitably to the stakeholder of interest. By formalizing supporting premises—and inferences—we can map stakeholder characteristics to those of explanation techniques. This allows us to reason over the techniques and prioritise the best one for the given context, while also offering transparency into the selection decision. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">MethnaniEtAl2024ClashOfExplainers</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Methnani, Leila and Dignum, Virginia and Theodorou, Andreas}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Artificial Intelligence. ECAI 2023 : XAI^3, TACTIFUL, XI-ML, SEDAMI, RAAIT, AI4S, HYDRA, AI4AI, Kraków, Poland, September 30 - October 4, 2023, Proceedings, Part I}</span><span class="p">,</span>
  <span class="na">institution</span> <span class="p">=</span> <span class="s">{Umeå University, Department of Computing Science}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{7--23}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Clash of the explainers : argumentation for context-appropriate explanations}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Communications in Computer and Information Science}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-3-031-50396-2_1}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{978-3-031-50396-2}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ff7802"> <div style="color:white">Proceedings</div> </abbr> <keyword class="badge rounded w-100" style="background-color:#154e54"> <div style="color:white">XAI</div> </keyword> </div> <div id="FaubelEtAl2024MLOPs" class="col-sm-8"> <div class="title">A MLOps Architecture for XAI in Industrial Applications</div> <div class="author"> Leonhard Faubel, Thomas Woudsma, Leila Methnani, Amir Ghorbani Ghezeljhemeidan, Fabian Buelow, Klaus Schmid, and <span class="more-authors" title="click to view 5 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '5 more authors' ? 'Willem D. Driel, Benjamin Kloepper, Andreas Theodorou, Mohsen Nosratinia, Magnus Bång' : '5 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">5 more authors</span> </div> <div class="periodical"> <em>In 2024 IEEE 29th International Conference on Emerging Technologies and Factory Automation (ETFA)</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1109/ETFA61755.2024.10711084" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> <span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=JEw-BycAAAAJ&amp;citation_for_view=JEw-BycAAAAJ:HoB7MX3m0LUC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-7-4285F4?logo=googlescholar&amp;labelColor=beige" alt="7 Google Scholar citations"> </a> </span> <span class="__dimensions_badge_embed__" data-doi="10.1109/ETFA61755.2024.10711084" data-style="small_rectangle" data-legend="hover-right" data-hide-zero-citations="true" style="margin-bottom: 2px;"></span> <span class="altmetric-embed" data-badge-type="2" data-badge-popover="right" data-hide-no-mentions="true" data-doi="10.1109/ETFA61755.2024.10711084" style="padding-right:0rem"></span> <span> <a href="https://plu.mx/plum/a/?doi=10.1109/ETFA61755.2024.10711084" data-popup="right" data-size="small" class="plumx-plum-print-popup" data-site="plum" data-hide-when-empty="true" rel="external nofollow noopener" target="_blank"> </a> </span> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">FaubelEtAl2024MLOPs</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Faubel, Leonhard and Woudsma, Thomas and Methnani, Leila and Ghezeljhemeidan, Amir Ghorbani and Buelow, Fabian and Schmid, Klaus and van Driel, Willem D. and Kloepper, Benjamin and Theodorou, Andreas and Nosratinia, Mohsen and Bång, Magnus}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2024 IEEE 29th International Conference on Emerging Technologies and Factory Automation (ETFA)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A MLOps Architecture for XAI in Industrial Applications}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1-4}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ETFA61755.2024.10711084}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#7c4242"> <div style="color:white">Book Chapter</div> </abbr> <keyword class="badge rounded w-100" style="background-color:#851868"> <div style="color:white">Governance</div> </keyword> </div> <div id="TheodorouAler2024RAIAtWork" class="col-sm-8"> <div class="title">Responsible AI at work : incorporating human values</div> <div class="author"> <em>Andreas Theodorou</em> and Andrea Aler Tubella </div> <div class="periodical"> <em>In Handbook of artificial intelligence at work : interconnections and policy implications</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.4337/9781800889972.00010" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.e-elgar.com/shop/gbp/handbook-of-artificial-intelligence-at-work-9781800889965.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> <div class="badges"> <span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=JEw-BycAAAAJ&amp;citation_for_view=JEw-BycAAAAJ:vV6vV6tmYwMC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-6-4285F4?logo=googlescholar&amp;labelColor=beige" alt="6 Google Scholar citations"> </a> </span> <span class="__dimensions_badge_embed__" data-doi="10.4337/9781800889972.00010" data-style="small_rectangle" data-legend="hover-right" data-hide-zero-citations="true" style="margin-bottom: 2px;"></span> <span class="altmetric-embed" data-badge-type="2" data-badge-popover="right" data-hide-no-mentions="true" data-doi="10.4337/9781800889972.00010" style="padding-right:0rem"></span> <span> <a href="https://plu.mx/plum/a/?doi=10.4337/9781800889972.00010" data-popup="right" data-size="small" class="plumx-plum-print-popup" data-site="plum" data-hide-when-empty="true" rel="external nofollow noopener" target="_blank"> </a> </span> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@incollection</span><span class="p">{</span><span class="nl">TheodorouAler2024RAIAtWork</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Theodorou, Andreas and Aler Tubella, Andrea}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Handbook of artificial intelligence at work : interconnections and policy implications}</span><span class="p">,</span>
  <span class="na">institution</span> <span class="p">=</span> <span class="s">{Umeå University, Department of Computing Science}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{32--46}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Responsible AI at work : incorporating human values}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.e-elgar.com/shop/gbp/handbook-of-artificial-intelligence-at-work-9781800889965.html}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9781800889965}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.4337/9781800889972.00010}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ff7802"> <div style="color:white">Proceedings</div> </abbr> <keyword class="badge rounded w-100" style="background-color:#851868"> <div style="color:white">Governance</div> </keyword> <keyword class="badge rounded w-100" style="background-color:#79BAEC"> <div style="color:white">Pedagogy</div> </keyword> </div> <div id="MethnaniEtAl2023ACAI" class="col-sm-8"> <div class="title">Operationalising AI ethics : conducting socio-technical assessment</div> <div class="author"> Leila Methnani, Mattias Brännström, and <em>Andreas Theodorou</em> </div> <div class="periodical"> <em>In Human-Centered Artificial Intelligence : Advanced Lectures</em>, 2023 </div> <div class="periodical"> Part of the book sub series: Lecture Notes in Artificial Intelligence (LNAI)Conference series: ACAI: ECCAI Advanced Course on Artificial Intelligence </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1007/978-3-031-24349-3_16" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> <span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=JEw-BycAAAAJ&amp;citation_for_view=JEw-BycAAAAJ:blknAaTinKkC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-2-4285F4?logo=googlescholar&amp;labelColor=beige" alt="2 Google Scholar citations"> </a> </span> <span class="__dimensions_badge_embed__" data-doi="10.1007/978-3-031-24349-3_16" data-style="small_rectangle" data-legend="hover-right" data-hide-zero-citations="true" style="margin-bottom: 2px;"></span> <span class="altmetric-embed" data-badge-type="2" data-badge-popover="right" data-hide-no-mentions="true" data-doi="10.1007/978-3-031-24349-3_16" style="padding-right:0rem"></span> <span> <a href="https://plu.mx/plum/a/?doi=10.1007/978-3-031-24349-3_16" data-popup="right" data-size="small" class="plumx-plum-print-popup" data-site="plum" data-hide-when-empty="true" rel="external nofollow noopener" target="_blank"> </a> </span> </div> <div class="abstract hidden"> <p>Several high profile incidents that involve Artificial Intelligence (AI) have captured public attention and increased demand for regulation. Low public trust and attitudes towards AI reinforce the need for concrete policy around its development and use. However, current guidelines and standards rolled out by institutions globally are considered by many as high-level and open to interpretation, making them difficult to put into practice. This paper presents ongoing research in the field of Responsible AI and explores numerous methods of operationalising AI ethics. If AI is to be effectively regulated, it must not be considered as a technology alone—AI is embedded in the fabric of our societies and should thus be treated as a socio-technical system, requiring multi-stakeholder involvement and employment of continuous value-based methods of assessment. When putting guidelines and standards into practice, context is of critical importance. The methods and frameworks presented in this paper emphasise this need and pave the way towards operational AI ethics.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">MethnaniEtAl2023ACAI</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Methnani, Leila and Br{\"a}nnstr{\"o}m, Mattias and Theodorou, Andreas}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Human-Centered Artificial Intelligence : Advanced Lectures}</span><span class="p">,</span>
  <span class="na">institution</span> <span class="p">=</span> <span class="s">{Umeå University, Department of Computing Science}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{Part of the book sub series: Lecture Notes in Artificial Intelligence (LNAI)Conference series: ACAI: ECCAI Advanced Course on Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{304--321}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Operationalising AI ethics : conducting socio-technical assessment}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{Lecture Notes in Computer Science}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{13500}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-3-031-24349-3_16}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9783031243486}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#b31b1b"> <div style="color:white">Preprint</div> </abbr> <keyword class="badge rounded w-100" style="background-color:#4169E1"> <div style="color:white">MLOPs</div> </keyword> <keyword class="badge rounded w-100" style="background-color:#154e54"> <div style="color:white">XAI</div> </keyword> </div> <div id="faubel2023mlopsarchitecturexaiindustrial" class="col-sm-8"> <div class="title">Towards an MLOps Architecture for XAI in Industrial Applications</div> <div class="author"> Leonhard Faubel, Thomas Woudsma, Leila Methnani, Amir Ghorbani Ghezeljhemeidan, Fabian Buelow, Klaus Schmid, and <span class="more-authors" title="click to view 5 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '5 more authors' ? 'Willem D. Driel, Benjamin Kloepper, Andreas Theodorou, Mohsen Nosratinia, Magnus Bång' : '5 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">5 more authors</span> </div> <div class="periodical"> 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.48550/arXiv.2309.12756" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/abs/2309.12756" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> <div class="badges"> <span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=JEw-BycAAAAJ&amp;citation_for_view=JEw-BycAAAAJ:ns9cj8rnVeAC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-10-4285F4?logo=googlescholar&amp;labelColor=beige" alt="10 Google Scholar citations"> </a> </span> <span class="__dimensions_badge_embed__" data-doi="10.48550/arXiv.2309.12756" data-style="small_rectangle" data-legend="hover-right" data-hide-zero-citations="true" style="margin-bottom: 2px;"></span> <span class="altmetric-embed" data-badge-type="2" data-badge-popover="right" data-hide-no-mentions="true" data-arxiv-id="2309.12756" style="padding-right:0rem"></span> <span> <a href="https://plu.mx/plum/a/?doi=10.48550/arXiv.2309.12756" data-popup="right" data-size="small" class="plumx-plum-print-popup" data-site="plum" data-hide-when-empty="true" rel="external nofollow noopener" target="_blank"> </a> </span> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">faubel2023mlopsarchitecturexaiindustrial</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Towards an MLOps Architecture for XAI in Industrial Applications}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Faubel, Leonhard and Woudsma, Thomas and Methnani, Leila and Ghezeljhemeidan, Amir Ghorbani and Buelow, Fabian and Schmid, Klaus and van Driel, Willem D. and Kloepper, Benjamin and Theodorou, Andreas and Nosratinia, Mohsen and Bång, Magnus}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{cs.SE}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2309.12756}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.48550/arXiv.2309.12756}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ff7802"> <div style="color:white">Proceedings</div> </abbr> <keyword class="badge rounded w-100" style="background-color:#355E3B"> <div style="color:white">Human Control</div> </keyword> </div> <div id="ChiouEtAl2023VAT" class="col-sm-8"> <div class="title">Variable Autonomy for Human-Robot Teaming (VAT)</div> <div class="author"> Manolis Chiou, Serena Booth, Bruno Lacerda, <em>Andreas Theodorou</em>, and Simon Rothfuß </div> <div class="periodical"> <em>In HRI ’23 : Companion of the 2023 ACM/IEEE International Conference on Human-Robot Interaction</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1145/3568294.3579957" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> <span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=JEw-BycAAAAJ&amp;citation_for_view=JEw-BycAAAAJ:M3NEmzRMIkIC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-5-4285F4?logo=googlescholar&amp;labelColor=beige" alt="5 Google Scholar citations"> </a> </span> <span class="__dimensions_badge_embed__" data-doi="10.1145/3568294.3579957" data-style="small_rectangle" data-legend="hover-right" data-hide-zero-citations="true" style="margin-bottom: 2px;"></span> <span class="altmetric-embed" data-badge-type="2" data-badge-popover="right" data-hide-no-mentions="true" data-doi="10.1145/3568294.3579957" style="padding-right:0rem"></span> <span> <a href="https://plu.mx/plum/a/?doi=10.1145/3568294.3579957" data-popup="right" data-size="small" class="plumx-plum-print-popup" data-site="plum" data-hide-when-empty="true" rel="external nofollow noopener" target="_blank"> </a> </span> </div> <div class="abstract hidden"> <p>As robots are introduced to various domains and applications, Human-Robot Teaming (HRT) capabilities are essential. Such capabilities involve teaming with humans in/on/out-the-loop at different levels of abstraction, leveraging the complementing capabilities of humans and robots. This requires robotic systems with the ability to dynamically vary their level or degree of autonomy to collaborate with the human(s) efficiently and overcome various challenging circumstances. Variable Autonomy (VA) is an umbrella term encompassing such research, including but not limited to shared control and shared autonomy, mixed-initiative, adjustable autonomy, and sliding autonomy. This workshop is driven by the timely need to bring together VA-related research and practices that are often disconnected across different communities as the field is relatively young. The workshop’s goal is to consolidate research in VA. To this end, and given the complexity and span of Human-Robot systems, this workshop will adopt a holistic trans-disciplinary approach aiming to a) identify and classify related common challenges and opportunities; b) identify the disciplines that need to come together to tackle the challenges; c) identify and define common terminology, approaches, methodologies, benchmarks, and metrics; d) define short- and longterm research goals for the community. To achieve these objectives, this workshop aims to bring together industry stakeholders, researchers from fields under the banner of VA, and specialists from other highly related fields such as human factors and psychology. The workshop will consist of a mix of invited talks, contributed papers, and an interactive discussion panel, toward a shared vision for VA. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">ChiouEtAl2023VAT</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Chiou, Manolis and Booth, Serena and Lacerda, Bruno and Theodorou, Andreas and Rothfuß, Simon}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{HRI '23 : Companion of the 2023 ACM/IEEE International Conference on Human-Robot Interaction}</span><span class="p">,</span>
  <span class="na">institution</span> <span class="p">=</span> <span class="s">{Karlsruhe Institute of Technology, Karlsruhe, Germany}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{932--932}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Variable Autonomy for Human-Robot Teaming (VAT)}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{ACM/IEEE International Conference on Human-Robot Interaction}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1145/3568294.3579957}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{978-1-4503-9970-8}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#b31b1b"> <div style="color:white">Preprint</div> </abbr> <keyword class="badge rounded w-100" style="background-color:#355E3B"> <div style="color:white">Human Control</div> </keyword> <keyword class="badge rounded w-100" style="background-color:#154e54"> <div style="color:white">Transparency</div> </keyword> </div> <div id="ramesh2023robothealthindicatorvisual" class="col-sm-8"> <div class="title">Robot Health Indicator: A Visual Cue to Improve Level of Autonomy Switching Systems</div> <div class="author"> Aniketh Ramesh, Madeleine Englund, <em>Andreas Theodorou</em>, Rustam Stolkin, and Manolis Chiou </div> <div class="periodical"> 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://arxiv.org/abs/2303.06776" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> <div class="badges"> <span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=JEw-BycAAAAJ&amp;citation_for_view=JEw-BycAAAAJ:JV2RwH3_ST0C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-6-4285F4?logo=googlescholar&amp;labelColor=beige" alt="6 Google Scholar citations"> </a> </span> <span class="__dimensions_badge_embed__" data-pmid="" data-style="small_rectangle" data-legend="hover-right" data-hide-zero-citations="true" style="margin-bottom: 2px;"></span> <span class="altmetric-embed" data-badge-type="2" data-badge-popover="right" data-hide-no-mentions="true" data-arxiv-id="2303.06776" style="padding-right:0rem"></span> <span> <a href="https://plu.mx/plum/a/?doi=" data-popup="right" data-size="small" class="plumx-plum-print-popup" data-site="plum" data-hide-when-empty="true" rel="external nofollow noopener" target="_blank"> </a> </span> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@misc</span><span class="p">{</span><span class="nl">ramesh2023robothealthindicatorvisual</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Robot Health Indicator: A Visual Cue to Improve Level of Autonomy Switching Systems}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ramesh, Aniketh and Englund, Madeleine and Theodorou, Andreas and Stolkin, Rustam and Chiou, Manolis}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">primaryclass</span> <span class="p">=</span> <span class="s">{cs.RO}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://arxiv.org/abs/2303.06776}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#950000"> <div style="color:white">Editorial</div> </abbr> <keyword class="badge rounded w-100" style="background-color:#851868"> <div style="color:white">Governance</div> </keyword> </div> <div id="BaumEtAl2023FromFearToAction" class="col-sm-8"> <div class="title">From fear to action : AI governance and opportunities for all</div> <div class="author"> Kevin Baum, Joanna Bryson, Frank Dignum, Virginia Dignum, Marko Grobelnik, Holger Hoos, and <span class="more-authors" title="click to view 7 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '7 more authors' ? 'Morten Irgens, Paul Lukowicz, Catelijne Muller, Francesca Rossi, John Shawe-Taylor, Andreas Theodorou, Ricardo Vinuesa' : '7 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">7 more authors</span> </div> <div class="periodical"> <em>Frontiers in Computer Science</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.3389/fcomp.2023.1210421" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> <span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=JEw-BycAAAAJ&amp;citation_for_view=JEw-BycAAAAJ:NMxIlDl6LWMC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-31-4285F4?logo=googlescholar&amp;labelColor=beige" alt="31 Google Scholar citations"> </a> </span> <span class="__dimensions_badge_embed__" data-doi="10.3389/fcomp.2023.1210421" data-style="small_rectangle" data-legend="hover-right" data-hide-zero-citations="true" style="margin-bottom: 2px;"></span> <span class="altmetric-embed" data-badge-type="2" data-badge-popover="right" data-hide-no-mentions="true" data-doi="10.3389/fcomp.2023.1210421" style="padding-right:0rem"></span> <span> <a href="https://plu.mx/plum/a/?doi=10.3389/fcomp.2023.1210421" data-popup="right" data-size="small" class="plumx-plum-print-popup" data-site="plum" data-hide-when-empty="true" rel="external nofollow noopener" target="_blank"> </a> </span> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">BaumEtAl2023FromFearToAction</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Baum, Kevin and Bryson, Joanna and Dignum, Frank and Dignum, Virginia and Grobelnik, Marko and Hoos, Holger and Irgens, Morten and Lukowicz, Paul and Muller, Catelijne and Rossi, Francesca and Shawe-Taylor, John and Theodorou, Andreas and Vinuesa, Ricardo}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Frontiers in Computer Science}</span><span class="p">,</span>
  <span class="na">eid</span> <span class="p">=</span> <span class="s">{1210421}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{From fear to action : AI governance and opportunities for all}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{5}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.3389/fcomp.2023.1210421}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#af0000"> <div style="color:white">Journal</div> </abbr> <keyword class="badge rounded w-100" style="background-color:#851868"> <div style="color:white">Governance</div> </keyword> </div> <div id="Bogani1706385" class="col-sm-8"> <div class="title">Garbage in, toxic data out : a proposal for ethical artificial intelligence sustainability impact statements</div> <div class="author"> Ronny Bogani, <em>Andreas Theodorou</em>, Luca Arnaboldi, and Robert H. Wortham </div> <div class="periodical"> <em>AI and Ethics</em>, 2023 </div> <div class="periodical"> Published online: 20 October 2022 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1007/s43681-022-00221-0" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> <span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=JEw-BycAAAAJ&amp;citation_for_view=JEw-BycAAAAJ:isC4tDSrTZIC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-12-4285F4?logo=googlescholar&amp;labelColor=beige" alt="12 Google Scholar citations"> </a> </span> <span class="__dimensions_badge_embed__" data-doi="10.1007/s43681-022-00221-0" data-style="small_rectangle" data-legend="hover-right" data-hide-zero-citations="true" style="margin-bottom: 2px;"></span> <span class="altmetric-embed" data-badge-type="2" data-badge-popover="right" data-hide-no-mentions="true" data-doi="10.1007/s43681-022-00221-0" style="padding-right:0rem"></span> <span> <a href="https://plu.mx/plum/a/?doi=10.1007/s43681-022-00221-0" data-popup="right" data-size="small" class="plumx-plum-print-popup" data-site="plum" data-hide-when-empty="true" rel="external nofollow noopener" target="_blank"> </a> </span> </div> <div class="abstract hidden"> <p>Data and autonomous systems are taking over our lives, from healthcare to smart homes very few aspects of our day to day are not permeated by them. The technological advances enabled by these technologies are limitless. However, with advantages so too come challenges. As these technologies encompass more and more aspects of our lives, we are forgetting the ethical, legal, safety and moral concerns that arise as an outcome of integrating our lives with technology. In this work, we study the lifecycle of artificial intelligence from data gathering to deployment, providing a structured analytical assessment of the potential ethical, safety and legal concerns. The paper then presents the foundations for the first ethical artificial intelligence sustainability statement to guide future development of AI in a safe and sustainable manner. </p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Bogani1706385</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Bogani, Ronny and Theodorou, Andreas and Arnaboldi, Luca and Wortham, Robert H.}</span><span class="p">,</span>
  <span class="na">institution</span> <span class="p">=</span> <span class="s">{Department of Electrical Engineering, University of Bath, Bath, UK}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{AI and Ethics}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{Published online: 20 October 2022}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1135--1142}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Garbage in, toxic data out : a proposal for ethical artificial intelligence sustainability impact statements}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{3}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/s43681-022-00221-0}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ff7802"> <div style="color:white">Proceedings</div> </abbr> <keyword class="badge rounded w-100" style="background-color:#851868"> <div style="color:white">Governance</div> </keyword> <keyword class="badge rounded w-100" style="background-color:#FFDA03"> <div style="color:white">Safety</div> </keyword> </div> <div id="BrannstromEtAl2022AISafety" class="col-sm-8"> <div class="title">Let it RAIN for Social Good</div> <div class="author"> Mattias Brännström, <em>Andreas Theodorou</em>, and Virginia Dignum </div> <div class="periodical"> <em>In IJCAI 2022 Workshop on AISafety</em>, 2022 </div> <div class="periodical"> Best paper award. </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2208.04697" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> <span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=JEw-BycAAAAJ&amp;citation_for_view=JEw-BycAAAAJ:r0BpntZqJG4C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-12-4285F4?logo=googlescholar&amp;labelColor=beige" alt="12 Google Scholar citations"> </a> </span> <span class="__dimensions_badge_embed__" data-pmid="" data-style="small_rectangle" data-legend="hover-right" data-hide-zero-citations="true" style="margin-bottom: 2px;"></span> <span class="altmetric-embed" data-badge-type="2" data-badge-popover="right" data-hide-no-mentions="true" data-arxiv-id="2208.04697" style="padding-right:0rem"></span> <span> <a href="https://plu.mx/plum/a/?doi=" data-popup="right" data-size="small" class="plumx-plum-print-popup" data-site="plum" data-hide-when-empty="true" rel="external nofollow noopener" target="_blank"> </a> </span> </div> <div class="abstract hidden"> <p>Artificial Intelligence (AI) as a highly transformative technology take on a special role as both an enabler and a threat to UN Sustainable Development Goals (SDGs). AI Ethics and emerging high-level policy efforts stand at the pivot point between these outcomes but is barred from effect due the abstraction gap between high-level values and responsible action. In this paper the Responsible Norms (RAIN) framework is presented, bridging this gap thereby enabling effective high-level control of AI impact. With effective and operationalized AI Ethics, AI technologies can be directed towards global sustainable development.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">BrannstromEtAl2022AISafety</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Brännström, Mattias and Theodorou, Andreas and Dignum, Virginia}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Let it {RAIN} for Social Good}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IJCAI 2022 Workshop on AISafety}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{Best paper award.}</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ff7802"> <div style="color:white">Proceedings</div> </abbr> <keyword class="badge rounded w-100" style="background-color:#5dd655"> <div style="color:white">Games AI</div> </keyword> <keyword class="badge rounded w-100">MAS</keyword> </div> <div id="MethnaniEtAl2022COINE" class="col-sm-8"> <div class="title">Embracing AWKWARD! Real-time Adjustment of Reactive Planning Using Social Norms</div> <div class="author"> Leila Methnani, Andreas Antoniades, and <em>Andreas Theodorou</em> </div> <div class="periodical"> <em>In Proceedings of the Coordination, Organizations, Institutions, Norms, and Ethics for Governance of Multi-Agent Systems (COINE) 2022</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1007/978-3-031-20845-4_4" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://dl.acm.org/doi/10.1007/978-3-031-20845-4_4" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> <div class="badges"> <span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=JEw-BycAAAAJ&amp;citation_for_view=JEw-BycAAAAJ:4JMBOYKVnBMC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-3-4285F4?logo=googlescholar&amp;labelColor=beige" alt="3 Google Scholar citations"> </a> </span> <span class="__dimensions_badge_embed__" data-doi="10.1007/978-3-031-20845-4_4" data-style="small_rectangle" data-legend="hover-right" data-hide-zero-citations="true" style="margin-bottom: 2px;"></span> <span class="altmetric-embed" data-badge-type="2" data-badge-popover="right" data-hide-no-mentions="true" data-doi="10.1007/978-3-031-20845-4_4" style="padding-right:0rem"></span> <span> <a href="https://plu.mx/plum/a/?doi=10.1007/978-3-031-20845-4_4" data-popup="right" data-size="small" class="plumx-plum-print-popup" data-site="plum" data-hide-when-empty="true" rel="external nofollow noopener" target="_blank"> </a> </span> </div> <div class="abstract hidden"> <p>This paper presents the AWKWARD architecture for the development of hybrid agents in Multi-Agent Systems. AWKWARD agents can have their plans re-configured in real time to align with social role requirements under changing environmental and social circumstances. The proposed hybrid architecture makes use of Behaviour Oriented Design (BOD) to develop agents with reactive planning and of the well-established OperA framework to provide organisational, social, and interaction definitions in order to validate and adjust agents’ behaviours. Together, OperA and BOD can achieve real-time adjustment of agent plans for evolving social roles, while providing the additional benefit of transparency into the interactions that drive this behavioural change in individual agents. We present this architecture to motivate the bridging between traditional symbolic- and behaviour-based AI communities, where such combined solutions can help MAS researchers in their pursuit of building stronger, more robust intelligent agent teams. We use DOTA2—a game where success is heavily dependent on social interactions—as a medium to demonstrate a sample implementation of our proposed hybrid architecture.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">MethnaniEtAl2022COINE</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Methnani, Leila and Antoniades, Andreas and Theodorou, Andreas}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Embracing {AWKWARD}! Real-time Adjustment of Reactive Planning Using Social Norms}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the Coordination, Organizations, Institutions, Norms, and Ethics for Governance of Multi-Agent Systems (COINE) 2022}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-3-031-20845-4_4}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://dl.acm.org/doi/10.1007/978-3-031-20845-4_4}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ff7802"> <div style="color:white">Proceedings</div> </abbr> <keyword class="badge rounded w-100" style="background-color:#851868"> <div style="color:white">Governance</div> </keyword> </div> <div id="TheodorouEtAl2022GoodAIforGood" class="col-sm-8"> <div class="title">Good AI for Good : How the AI strategies of the Nordic countries address the sustainable development goals</div> <div class="author"> <em>Andreas Theodorou</em>, Juan Carlos Nieves, and Virginia Dignum </div> <div class="periodical"> <em>In Proceedings of the 2nd Workshop on Adverse Impacts and Collateral Effects of AI Technologies</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ceur-ws.org/Vol-3275/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> <div class="badges"> <span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=JEw-BycAAAAJ&amp;citation_for_view=JEw-BycAAAAJ:4JMBOYKVnBMC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-3-4285F4?logo=googlescholar&amp;labelColor=beige" alt="3 Google Scholar citations"> </a> </span> <span> <a href="https://plu.mx/plum/a/?doi=" data-popup="right" data-size="small" class="plumx-plum-print-popup" data-site="plum" data-hide-when-empty="true" rel="external nofollow noopener" target="_blank"> </a> </span> </div> <div class="abstract hidden"> <p>Developed and used responsibly Artificial Intelligence (AI) is a force for global sustainable development. Given this opportunity, we expect that the many of the existing guidelines and recommendations for trustworthy or responsible AI will provide explicit guidance on how AI can contribute to the achievement of United Nations’ Sustainable Development Goals (SDGs). This would in particular be the case for the AI strategies of the Nordic countries, at least given their high ranking and overall political focus when it comes to the achievement of the SDGs. In this paper, we present an analysis of existing AI recommendations from 10 different countries or organisations based on topic modelling techniques to identify how much these strategy documents refer to the SDGs. The analysis shows no significant difference on how much these documents refer to SDGs. Moreover, the Nordic countries are not different from the others albeit their long-term commitment to SDGs. More importantly, references to gender equality (SDG 5) and inequality (SDG 10), as well as references to environmental impact of AI development and use, and in particular the consequences for life on earth, are notably missing from the guidelines.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">TheodorouEtAl2022GoodAIforGood</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Theodorou, Andreas and Nieves, {Juan Carlos} and Dignum, Virginia}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 2nd Workshop on Adverse Impacts and Collateral Effects of AI Technologies}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{46--53}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{CEUR-WS}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Good AI for Good : How the AI strategies of the Nordic countries address the sustainable development goals}</span><span class="p">,</span>
  <span class="na">series</span> <span class="p">=</span> <span class="s">{CEUR Workshop Proceedings}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{3275}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ceur-ws.org/Vol-3275/}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#af0000"> <div style="color:white">Journal</div> </abbr> <keyword class="badge rounded w-100" style="background-color:#851868"> <div style="color:white">Governance</div> </keyword> <keyword class="badge rounded w-100" style="background-color:#154e54"> <div style="color:white">Fairness</div> </keyword> </div> <div id="SartoriTheodorou2022" class="col-sm-8"> <div class="title">A sociotechnical perspective for the future of AI: narratives, inequalities, and human control</div> <div class="author"> Laura Sartori and <em>Andreas Theodorou</em> </div> <div class="periodical"> <em>Ethics of Information Technology</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1007/s10676-022-09624-3" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://link.springer.com/article/10.1007/s10676-022-09624-3" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> <div class="badges"> <span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=JEw-BycAAAAJ&amp;citation_for_view=JEw-BycAAAAJ:R3hNpaxXUhUC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-304-4285F4?logo=googlescholar&amp;labelColor=beige" alt="304 Google Scholar citations"> </a> </span> <span class="__dimensions_badge_embed__" data-doi="10.1007/s10676-022-09624-3" data-style="small_rectangle" data-legend="hover-right" data-hide-zero-citations="true" style="margin-bottom: 2px;"></span> <span class="altmetric-embed" data-badge-type="2" data-badge-popover="right" data-hide-no-mentions="true" data-doi="10.1007/s10676-022-09624-3" style="padding-right:0rem"></span> <span> <a href="https://plu.mx/plum/a/?doi=10.1007/s10676-022-09624-3" data-popup="right" data-size="small" class="plumx-plum-print-popup" data-site="plum" data-hide-when-empty="true" rel="external nofollow noopener" target="_blank"> </a> </span> </div> <div class="abstract hidden"> <p>Different people have different perceptions about artificial intelligence (AI). It is extremely important to bring together all the alternative frames of thinking—from the various communities of developers, researchers, business leaders, policymakers, and citizens—to properly start acknowledging AI. This article highlights the ‘fruitful collaboration’ that sociology and AI could develop in both social and technical terms. We discuss how biases and unfairness are among the major challenges to be addressed in such a sociotechnical perspective. First, as intelligent machines reveal their nature of ‘magnifying glasses’ in the automation of existing inequalities, we show how the AI technical community is calling for transparency and explainability, accountability and contestability. Not to be considered as panaceas, they all contribute to ensuring human control in novel practices that include requirement, design and development methodologies for a fairer AI. Second, we elaborate on the mounting attention for technological narratives as technology is recognized as a social practice within a specific institutional context. Not only do narratives reflect organizing visions for society, but they also are a tangible sign of the traditional lines of social, economic, and political inequalities. We conclude with a call for a diverse approach within the AI community and a richer knowledge about narratives as they help in better addressing future technical developments, public debate, and policy. AI practice is interdisciplinary by nature and it will benefit from a socio-technical perspective.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">SartoriTheodorou2022</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Sartori, Laura and Theodorou, Andreas}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A sociotechnical perspective for the future of AI: narratives, inequalities, and human control}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Ethics of Information Technology}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/s10676-022-09624-3}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://link.springer.com/article/10.1007/s10676-022-09624-3}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{24}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2021</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#af0000"> <div style="color:white">Journal</div> </abbr> <keyword class="badge rounded w-100" style="background-color:#355E3B"> <div style="color:white">Human Control</div> </keyword> <keyword class="badge rounded w-100" style="background-color:#851868"> <div style="color:white">Governance</div> </keyword> </div> <div id="Methnani2021Frontiers" class="col-sm-8"> <div class="title">Let Me Take Over: Variable Autonomy For Meaningful Human Control</div> <div class="author"> Leila Methnani, Andrea Aler Tubella, Virginia Dignum, and <em>Andreas Theodorou</em> </div> <div class="periodical"> <em>Frontiers in Artificial Intelligence</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.3389/frai.2021.737072" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.frontiersin.org/article/10.3389/frai.2021.737072" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> <div class="badges"> <span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=JEw-BycAAAAJ&amp;citation_for_view=JEw-BycAAAAJ:mB3voiENLucC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-92-4285F4?logo=googlescholar&amp;labelColor=beige" alt="92 Google Scholar citations"> </a> </span> <span class="__dimensions_badge_embed__" data-doi="10.3389/frai.2021.737072" data-style="small_rectangle" data-legend="hover-right" data-hide-zero-citations="true" style="margin-bottom: 2px;"></span> <span class="altmetric-embed" data-badge-type="2" data-badge-popover="right" data-hide-no-mentions="true" data-altmetric-id="112505452" style="padding-right:0rem"></span> <span> <a href="https://plu.mx/plum/a/?doi=10.3389/frai.2021.737072" data-popup="right" data-size="small" class="plumx-plum-print-popup" data-site="plum" data-hide-when-empty="true" rel="external nofollow noopener" target="_blank"> </a> </span> </div> <div class="abstract hidden"> <p>As Artificial Intelligence (AI) continues to expand its reach, the demand for human control and the development of AI systems that adhere to our legal, ethical, and social values also grows. Many (international and national) institutions have taken steps in this direction and published guidelines for the development and deployment of responsible AI systems. These guidelines, however, rely heavily on high-level statements that provide no clear criteria for system assessment, making the effective control over systems a challenge. “Human oversight” is one of the requirements being put forward as a means to support human autonomy and agency. In this paper, we argue that human presence alone does not meet this requirement and that such a misconception may limit the use of automation where it can otherwise provide so much benefit across industries. We therefore propose the development of systems with variable autonomy—dynamically adjustable levels of autonomy—as a means of ensuring meaningful human control over an artefact by satisfying all three core values commonly advocated in ethical guidelines: accountability, responsibility, and transparency.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Methnani2021Frontiers</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Methnani, Leila and {Aler Tubella}, Andrea and Dignum, Virginia and Theodorou, Andreas}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Let Me Take Over: Variable Autonomy For Meaningful Human Control}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Frontiers in Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{4}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{133}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.frontiersin.org/article/10.3389/frai.2021.737072}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.3389/frai.2021.737072}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2624-8212}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#af0000"> <div style="color:white">Journal</div> </abbr> <keyword class="badge rounded w-100" style="background-color:#851868"> <div style="color:white">Governance</div> </keyword> <keyword class="badge rounded w-100" style="background-color:#154e54"> <div style="color:white">Transparency</div> </keyword> </div> <div id="WinfieldEtAl2021Frontiers" class="col-sm-8"> <div class="title">IEEE P7001: A Proposed Standard on Transparency</div> <div class="author"> Alan F. T. Winfield, Serena Booth, Louise A. Dennis, Takashi Egawa, Helen Hastie, Naomi Jacobs, and <span class="more-authors" title="click to view 7 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '7 more authors' ? 'Roderick I. Muttram, Joanna I. Olszewska, Fahimeh Rajabiyazdi, Andreas Theodorou, Mark A. Underwood, Robert H. Wortham, Eleanor Watson' : '7 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">7 more authors</span> </div> <div class="periodical"> <em>Frontiers in Robotics and AI</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.3389/frobt.2021.665729" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.frontiersin.org/article/10.3389/frobt.2021.665729" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> <div class="badges"> <span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=JEw-BycAAAAJ&amp;citation_for_view=JEw-BycAAAAJ:hFOr9nPyWt4C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-141-4285F4?logo=googlescholar&amp;labelColor=beige" alt="141 Google Scholar citations"> </a> </span> <span class="__dimensions_badge_embed__" data-doi="10.3389/frobt.2021.665729" data-style="small_rectangle" data-legend="hover-right" data-hide-zero-citations="true" style="margin-bottom: 2px;"></span> <span class="altmetric-embed" data-badge-type="2" data-badge-popover="right" data-hide-no-mentions="true" data-altmetric-id="110476625" style="padding-right:0rem"></span> <span> <a href="https://plu.mx/plum/a/?doi=10.3389/frobt.2021.665729" data-popup="right" data-size="small" class="plumx-plum-print-popup" data-site="plum" data-hide-when-empty="true" rel="external nofollow noopener" target="_blank"> </a> </span> </div> <div class="abstract hidden"> <p>This paper describes IEEE P7001, a new draft standard on transparency of autonomous systems<xref ref-type="fn" rid="fn1"><sup>1</sup></xref>. In the paper, we outline the development and structure of the draft standard. We present the rationale for transparency as a measurable, testable property. We outline five stakeholder groups: users, the general public and bystanders, safety certification agencies, incident/accident investigators and lawyers/expert witnesses, and explain the thinking behind the normative definitions of “levels” of transparency for each stakeholder group in P7001. The paper illustrates the application of P7001 through worked examples of both specification and assessment of fictional autonomous systems.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">WinfieldEtAl2021Frontiers</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Winfield, {Alan F. T}. and Booth, {Serena} and Dennis, {Louise A.} and Egawa, Takashi and Hastie, Helen and Jacobs, Naomi and Muttram, {Roderick I.} and Olszewska, {Joanna I.} and Rajabiyazdi, Fahimeh and Theodorou, Andreas and Underwood, {Mark A.} and Wortham, {Robert H.} and Watson, Eleanor}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{IEEE P7001: A Proposed Standard on Transparency}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Frontiers in Robotics and AI}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{8}</span><span class="p">,</span>
  <span class="na">issue</span> <span class="p">=</span> <span class="s">{665729}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.frontiersin.org/article/10.3389/frobt.2021.665729}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.3389/frobt.2021.665729}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{2296-9144}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ff7802"> <div style="color:white">Proceedings</div> </abbr> <keyword class="badge rounded w-100" style="background-color:#851868"> <div style="color:white">Governance</div> </keyword> <keyword class="badge rounded w-100" style="background-color:#154e54"> <div style="color:white">Transparency</div> </keyword> </div> <div id="AlerTubellaEtAl2021AAMAS" class="col-sm-8"> <div class="title">Interrogating the Black Box: Transparency through Information-Seeking Dialogues</div> <div class="author"> Andrea Aler Tubella, <em>Andreas Theodorou</em>, and Juan Carlos Nieves </div> <div class="periodical"> <em>In Proceedings of the 20th International Conference on Autonomous Agents and MultiAgent Systems</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.65109/ONBL7454" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="http://arxiv.org/abs/2102.04714" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> </div> <div class="badges"> <span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=JEw-BycAAAAJ&amp;citation_for_view=JEw-BycAAAAJ:IWHjjKOFINEC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-6-4285F4?logo=googlescholar&amp;labelColor=beige" alt="6 Google Scholar citations"> </a> </span> <span class="__dimensions_badge_embed__" data-doi="10.65109/ONBL7454" data-style="small_rectangle" data-legend="hover-right" data-hide-zero-citations="true" style="margin-bottom: 2px;"></span> <span class="altmetric-embed" data-badge-type="2" data-badge-popover="right" data-hide-no-mentions="true" data-arxiv-id="2102.04714" style="padding-right:0rem"></span> <span> <a href="https://plu.mx/plum/a/?doi=10.65109/ONBL7454" data-popup="right" data-size="small" class="plumx-plum-print-popup" data-site="plum" data-hide-when-empty="true" rel="external nofollow noopener" target="_blank"> </a> </span> </div> <div class="abstract hidden"> <p>This paper is preoccupied with the following question: given a (possibly opaque) learning system, how can we understand whether its behaviour adheres to governance constraints? The answer can be quite simple: we just need to "ask" the system about it. We propose to construct an investigator agent to query a learning agent– the suspect agent– to investigate its adherence to a given ethical policy in the context of an information-seeking dialogue, modeled in formal argumentation settings. This formal dialogue framework is the main contribution of this paper. Through it, we break down compliance checking mechanisms into three modular components, each of which can be tailored to various needs in a vast amount of ways: an investigator agent, a suspect agent, and an acceptance protocol determining whether the responses of the suspect agent comply with the policy. This acceptance protocol presents a fundamentally different approach to aggregation: rather than using quantitative methods to deal with the non-determinism of a learning system, we leverage the use of argumentation semantics to investigate the notion of properties holding consistently. Overall, we argue that the introduced formal dialogue framework opens many avenues both in the area of compliance checking and in the analysis of properties of opaque systems.</p> </div> </div> </div> </li> </ol> <h2 class="bibliography">2020</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">Report</abbr> <keyword class="badge rounded w-100" style="background-color:#851868"> <div style="color:white">Governance</div> </keyword> </div> <div id="MullerEtAl2020Analysis" class="col-sm-8"> <div class="title">Final Anaysis on the EU Whitepaper on AI</div> <div class="author"> Catelijne Muller, Virginia Dignum, and <em>Andreas Theodorou</em> </div> <div class="periodical"> 2020 </div> <div class="periodical"> </div> <div class="links"> <a href="https://tinyurl.com/yc6bw9bf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> <div class="badges"> <span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=JEw-BycAAAAJ&amp;citation_for_view=JEw-BycAAAAJ:maZDTaKrznsC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-3-4285F4?logo=googlescholar&amp;labelColor=beige" alt="3 Google Scholar citations"> </a> </span> <span> <a href="https://plu.mx/plum/a/?doi=" data-popup="right" data-size="small" class="plumx-plum-print-popup" data-site="plum" data-hide-when-empty="true" rel="external nofollow noopener" target="_blank"> </a> </span> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ff7802"> <div style="color:white">Proceedings</div> </abbr> <keyword class="badge rounded w-100" style="background-color:#851868"> <div style="color:white">Governance</div> </keyword> <keyword class="badge rounded w-100" style="background-color:#FFDA03"> <div style="color:white">Safety</div> </keyword> </div> <div id="AlerTubellaEtAl2020RULEML" class="col-sm-8"> <div class="title">Contestable Black Boxes</div> <div class="author"> Andrea Aler Tubella, <em>Andreas Theodorou</em>, Virginia Dignum, and Loizos Michael </div> <div class="periodical"> <em>In 4th International Joint Conference on Rules and Reasoning (RuleML)</em>, Jun 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1007/978-3-030-57977-7_12" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="http://arxiv.org/abs/2006.05133" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> <span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=JEw-BycAAAAJ&amp;citation_for_view=JEw-BycAAAAJ:4DMP91E08xMC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-29-4285F4?logo=googlescholar&amp;labelColor=beige" alt="29 Google Scholar citations"> </a> </span> <span class="__dimensions_badge_embed__" data-doi="10.1007/978-3-030-57977-7_12" data-style="small_rectangle" data-legend="hover-right" data-hide-zero-citations="true" style="margin-bottom: 2px;"></span> <span class="altmetric-embed" data-badge-type="2" data-badge-popover="right" data-hide-no-mentions="true" data-altmetric-id="88604415" style="padding-right:0rem"></span> <span> <a href="https://plu.mx/plum/a/?doi=10.1007/978-3-030-57977-7_12" data-popup="right" data-size="small" class="plumx-plum-print-popup" data-site="plum" data-hide-when-empty="true" rel="external nofollow noopener" target="_blank"> </a> </span> </div> <div class="abstract hidden"> <p>The right to contest a decision with consequences on individuals or the society is a well-established democratic right. Despite this right also being explicitly included in GDPR in reference to automated decision-making, its study seems to have received much less attention in the AI literature compared, for example, to the right for explanation. This paper investigates the type of assurances that are needed in the contesting process when algorithmic black-boxes are involved, opening new questions about the interplay of contestability and explainability. We argue that specialised complementary methodologies to evaluate automated decision-making in the case of a particular decision being contested need to be developed. Further, we propose a combination of well-established software engineering and rule-based approaches as a possible socio-technical solution to the issue of contestability, one of the new democratic challenges posed by the automation of decision making.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">AlerTubellaEtAl2020RULEML</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{{Aler Tubella}, Andrea and Theodorou, Andreas and Dignum, Virginia and Michael, Loizos}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{4th International Joint Conference on Rules and Reasoning (RuleML)}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jun</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Olso, Norway}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Contestable Black Boxes}}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-3-030-57977-7_12}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#af0000"> <div style="color:white">Journal</div> </abbr> <keyword class="badge rounded w-100" style="background-color:#851868"> <div style="color:white">Governance</div> </keyword> <keyword class="badge rounded w-100" style="background-color:#FFDA03"> <div style="color:white">Safety</div> </keyword> </div> <div id="VinuesaEtAl2020SocioTechnical" class="col-sm-8"> <div class="title">A socio-technical framework for digital contact tracing</div> <div class="author"> Ricardo Vinuesa, <em>Andreas Theodorou</em>, Manuela Battaglini, and Virginia Dignum </div> <div class="periodical"> <em>Results in Engineering</em>, 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1016/j.rineng.2020.100163" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="http://arxiv.org/abs/2005.08370" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> <span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=JEw-BycAAAAJ&amp;citation_for_view=JEw-BycAAAAJ:qxL8FJ1GzNcC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-67-4285F4?logo=googlescholar&amp;labelColor=beige" alt="67 Google Scholar citations"> </a> </span> <span class="__dimensions_badge_embed__" data-doi="10.1016/j.rineng.2020.100163" data-style="small_rectangle" data-legend="hover-right" data-hide-zero-citations="true" style="margin-bottom: 2px;"></span> <span class="altmetric-embed" data-badge-type="2" data-badge-popover="right" data-hide-no-mentions="true" data-arxiv-id="2005.08370" style="padding-right:0rem"></span> <span> <a href="https://plu.mx/plum/a/?doi=10.1016/j.rineng.2020.100163" data-popup="right" data-size="small" class="plumx-plum-print-popup" data-site="plum" data-hide-when-empty="true" rel="external nofollow noopener" target="_blank"> </a> </span> </div> <div class="abstract hidden"> <p>In their efforts to tackle the COVID-19 crisis, decision makers are considering the development and use of smartphone applications for contact tracing. Even though these applications differ in technology and methods, there is an increasing concern about their implications for privacy and human rights. Here we propose a framework to evaluate their suitability in terms of impact on the users, employed technology and governance methods. We illustrate its usage with three applications, and with the European Data Protection Board (EDPB) guidelines, highlighting their limitations.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">VinuesaEtAl2020SocioTechnical</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A socio-technical framework for digital contact tracing}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Vinuesa, Ricardo and Theodorou, Andreas and Battaglini, Manuela and Dignum, Virginia}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Results in Engineering}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1016/j.rineng.2020.100163}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#af0000"> <div style="color:white">Journal</div> </abbr> <keyword class="badge rounded w-100" style="background-color:#851868"> <div style="color:white">Governance</div> </keyword> </div> <div id="TheodorouDignum2020NMI" class="col-sm-8"> <div class="title">Towards ethical and socio-legal governance in AI</div> <div class="author"> <em>Andreas Theodorou</em> and Virginia Dignum </div> <div class="periodical"> <em>Nature Machine Intelligence</em>, 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1038/s42256-019-0136-y" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.nature.com/articles/s42256-019-0136-y.epdf?shared_access_token=tLQjOyEeJJBLNYBpYAddZ9RgN0jAjWel9jnR3ZoTv0OKielulWtfIKdoTkc7o23A4ag4RzhLocCFIkMqRYeFumYGAnLqPSfK_tQ3761isKFC32POZ17DGXFsQMNDEcD8X2AnDXspfKQtpudOtnxcvQ%3D%3D" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> <div class="badges"> <span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=JEw-BycAAAAJ&amp;citation_for_view=JEw-BycAAAAJ:YOwf2qJgpHMC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-201-4285F4?logo=googlescholar&amp;labelColor=beige" alt="201 Google Scholar citations"> </a> </span> <span class="__dimensions_badge_embed__" data-doi="10.1038/s42256-019-0136-y" data-style="small_rectangle" data-legend="hover-right" data-hide-zero-citations="true" style="margin-bottom: 2px;"></span> <span class="altmetric-embed" data-badge-type="2" data-badge-popover="right" data-hide-no-mentions="true" data-altmetric-id="74153933" style="padding-right:0rem"></span> <span> <a href="https://plu.mx/plum/a/?doi=10.1038/s42256-019-0136-y" data-popup="right" data-size="small" class="plumx-plum-print-popup" data-site="plum" data-hide-when-empty="true" rel="external nofollow noopener" target="_blank"> </a> </span> </div> <div class="abstract hidden"> <p>Many high-level ethics guidelines for AI have been produced in the past few years. It is time to work towards concrete policies within the context of existing moral, legal and cultural values, say Andreas Theodorou and Virginia Dignum...</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">TheodorouDignum2020NMI</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Theodorou, Andreas and Dignum, Virginia}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1038/s42256-019-0136-y}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Nature Machine Intelligence}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Towards ethical and socio-legal governance in AI}}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">issue</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{{https://www.nature.com/articles/s42256-019-0136-y.epdf?shared_access_token=tLQjOyEeJJBLNYBpYAddZ9RgN0jAjWel9jnR3ZoTv0OKielulWtfIKdoTkc7o23A4ag4RzhLocCFIkMqRYeFumYGAnLqPSfK_tQ3761isKFC32POZ17DGXFsQMNDEcD8X2AnDXspfKQtpudOtnxcvQ%3D%3D}}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#7c4242"> <div style="color:white">Book Chapter</div> </abbr> <keyword class="badge rounded w-100" style="background-color:#851868"> <div style="color:white">Governance</div> </keyword> </div> <div id="Theodorou2020AIReflections" class="col-sm-8"> <div class="title">Why Artificial Intelligence is a matter of Design</div> <div class="author"> <em>Andreas Theodorou</em> </div> <div class="periodical"> <em>In Artificial Intelligence: Reflections in Philosophy, Theology, and Social Sciences</em>, 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.30965/9783957437488_009" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> <span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=JEw-BycAAAAJ&amp;citation_for_view=JEw-BycAAAAJ:QIV2ME_5wuYC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-6-4285F4?logo=googlescholar&amp;labelColor=beige" alt="6 Google Scholar citations"> </a> </span> <span class="__dimensions_badge_embed__" data-doi="10.30965/9783957437488_009" data-style="small_rectangle" data-legend="hover-right" data-hide-zero-citations="true" style="margin-bottom: 2px;"></span> <span class="altmetric-embed" data-badge-type="2" data-badge-popover="right" data-hide-no-mentions="true" data-doi="10.30965/9783957437488_009" style="padding-right:0rem"></span> <span> <a href="https://plu.mx/plum/a/?doi=10.30965/9783957437488_009" data-popup="right" data-size="small" class="plumx-plum-print-popup" data-site="plum" data-hide-when-empty="true" rel="external nofollow noopener" target="_blank"> </a> </span> </div> <div class="abstract hidden"> <p>Unlike other human-made objects, the ability for intelligent systems to exhibit agency, and even appear anthropomorphic, leads to moral confusion about their status in society. As Himma states “If something walks, talks, and behaves enough like me, I might not be justified in thinking that it has a mind, but I surely have an obligation, if our ordinary reactions regarding other people are correct, to treat them as if they are moral agents.” Here, I present an evaluation of the requirements for moral agency and moral patiency. I examine human morality through a presentation of a high-level ontology of the human action-selection system. Then, drawing parallels between natural and artificial intelligence, I discuss the limitations and bottlenecks of intelligence, demonstrating how an ‘all-powerful’ Artificial General Intelligence would not only entail omniscience, but also be impossible. I demonstrate throughout this Chapter how culture determines the moral status of all entities, as morality and law are human-made ‘fictions’ that help us guide our actions. This means that our moral spectrum can be altered to include machines. However, there are both descriptive and normative arguments for why such a move is not only avoidable, but also should be avoided.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@incollection</span><span class="p">{</span><span class="nl">Theodorou2020AIReflections</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Theodorou, Andreas}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Artificial Intelligence: Reflections in Philosophy, Theology, and Social Sciences}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Goecke, Benedikt Paul and Rosenthal-von der P{\"{u}}tten, Astrid Marieke}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Brill}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Why Artificial Intelligence is a matter of Design}}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.30965/9783957437488_009}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2019</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#7c4242"> <div style="color:white">Book Chapter</div> </abbr> <keyword class="badge rounded w-100" style="background-color:#851868"> <div style="color:white">Governance</div> </keyword> <keyword class="badge rounded w-100" style="background-color:#80461B"> <div style="color:white">Cogn. Arch.</div> </keyword> </div> <div id="BrysonTheodorou2019" class="col-sm-8"> <div class="title">How Society Can Maintain Human-Centric Artificial Intelligence</div> <div class="author"> Joanna J Bryson and <em>Andreas Theodorou</em> </div> <div class="periodical"> <em>In Human-Centered Digitalization and Services</em>, 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1007/978-981-13-7725-9_16" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://www.cs.bath.ac.uk/%C2%A0jjb/web/publications.html%20http://link.springer.com/10.1007/978-981-13-7725-9_16" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> <div class="badges"> <span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=JEw-BycAAAAJ&amp;citation_for_view=JEw-BycAAAAJ:roLk4NBRz8UC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-162-4285F4?logo=googlescholar&amp;labelColor=beige" alt="162 Google Scholar citations"> </a> </span> <span class="__dimensions_badge_embed__" data-doi="10.1007/978-981-13-7725-9_16" data-style="small_rectangle" data-legend="hover-right" data-hide-zero-citations="true" style="margin-bottom: 2px;"></span> <span class="altmetric-embed" data-badge-type="2" data-badge-popover="right" data-hide-no-mentions="true" data-altmetric-id="145029433" style="padding-right:0rem"></span> <span> <a href="https://plu.mx/plum/a/?doi=10.1007/978-981-13-7725-9_16" data-popup="right" data-size="small" class="plumx-plum-print-popup" data-site="plum" data-hide-when-empty="true" rel="external nofollow noopener" target="_blank"> </a> </span> </div> <div class="abstract hidden"> <p>Although not a universally held goal, maintaining human-centric artificial intelligence is necessary for society’s long-term stability. Fortunately, the legal and technological problems of maintaining control are actually fairly well understood and amenable to engineering. The real problem is establishing the social and political will for assigning and maintaining accountability for artifacts when these artefacts are generated or used. In this chapter we review the necessity and tractability of maintaining human control, and the mechanisms by which this can be achieved. What makes the problem both most interesting and most threatening is that achieving consensus around such an approach requires at least some measure of agreement on broad existential concerns.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@incollection</span><span class="p">{</span><span class="nl">BrysonTheodorou2019</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Bryson, Joanna J and Theodorou, Andreas}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Human-Centered Digitalization and Services}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-981-13-7725-9_16}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Toivonen-Noro, Marja and Saari, Evelina and Melkas, Helin{\"{a}} and Hasu, Mervin}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{305--323}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Springer}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{How Society Can Maintain Human-Centric Artificial Intelligence}}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{http://www.cs.bath.ac.uk/{~}jjb/web/publications.html http://link.springer.com/10.1007/978-981-13-7725-9{\_}16}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ff7802"> <div style="color:white">Proceedings</div> </abbr> <keyword class="badge rounded w-100" style="background-color:#851868"> <div style="color:white">H-AI Int.</div> </keyword> <keyword class="badge rounded w-100" style="background-color:#154e54"> <div style="color:white">Transparency</div> </keyword> </div> <div id="RotsidisEtAl2019ROMAN" class="col-sm-8"> <div class="title">Improving Robot Transparency: An Investigation With Mobile Augmented Reality</div> <div class="author"> Alexandros Rotsidis, <em>Andreas Theodorou</em>, Joanna J. Bryson, and Robert H. Wortham </div> <div class="periodical"> <em>In 2019 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)</em>, Oct 2019 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1109/RO-MAN46459.2019.8956390" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/8956390/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> <div class="badges"> <span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=JEw-BycAAAAJ&amp;citation_for_view=JEw-BycAAAAJ:_Qo2XoVZTnwC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-36-4285F4?logo=googlescholar&amp;labelColor=beige" alt="36 Google Scholar citations"> </a> </span> <span class="__dimensions_badge_embed__" data-doi="10.1109/RO-MAN46459.2019.8956390" data-style="small_rectangle" data-legend="hover-right" data-hide-zero-citations="true" style="margin-bottom: 2px;"></span> <span class="altmetric-embed" data-badge-type="2" data-badge-popover="right" data-hide-no-mentions="true" data-doi="10.1109/RO-MAN46459.2019.8956390" style="padding-right:0rem"></span> <span> <a href="https://plu.mx/plum/a/?doi=10.1109/RO-MAN46459.2019.8956390" data-popup="right" data-size="small" class="plumx-plum-print-popup" data-site="plum" data-hide-when-empty="true" rel="external nofollow noopener" target="_blank"> </a> </span> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">RotsidisEtAl2019ROMAN</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New Delhi, India}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Rotsidis, Alexandros and Theodorou, Andreas and Bryson, Joanna J. and Wortham, Robert H.}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2019 28th IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/RO-MAN46459.2019.8956390}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{978-1-7281-2622-7}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1--8}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Improving Robot Transparency: An Investigation With Mobile Augmented Reality}}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ieeexplore.ieee.org/document/8956390/}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#800020"> <div style="color:white">Thesis</div> </abbr> </div> <div id="Theodorou2019Thesis" class="col-sm-8"> <div class="title">AI Governance Through a Transparency Lens</div> <div class="author"> <em>Andreas Theodorou</em> </div> <div class="periodical"> <em>University of Bath</em>, 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/RecklessCoding/recklesscoding.github.io/raw/master/files/andreasTheodorouThesis.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> <div class="badges"> <span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=JEw-BycAAAAJ&amp;citation_for_view=JEw-BycAAAAJ:KlAtU1dfN6UC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-4-4285F4?logo=googlescholar&amp;labelColor=beige" alt="4 Google Scholar citations"> </a> </span> <span> <a href="https://plu.mx/plum/a/?doi=" data-popup="right" data-size="small" class="plumx-plum-print-popup" data-site="plum" data-hide-when-empty="true" rel="external nofollow noopener" target="_blank"> </a> </span> </div> <div class="abstract hidden"> <p>Transparency is a key consideration for the ethical design and use of Artificial Intelligence, and has recently become a topic of considerable public interest and debate. We frequently use philosophical, mathematical, and biologically inspired techniques for building artificial, interactive, intelligent agents. Yet despite these well-motivated inspirations, the resulting intelligence is often developed as a black box, communicating no understanding of how the underlying real-time decision making functions. This compromises both the safety of such systems and fair attribution of moral responsibility and legal accountability when incidents occur. This dissertation provides the knowledge and software tools to make artificially intelligent agents more transparent, allowing a direct understanding of the action-selection system of such a system. The use of transparency, as demonstrated in this document, helps not only with the debugging of intelligent agents, but also with the public’s understanding of Artificial Intelligence (AI) by removing the ’scary’ mystery around "why is it behaving like that". In the research described in this document I investigate and compare the perception we have of intelligent systems, such as robots and autonomous vehicles, when they are treated as black boxes compared to when we make their action-selection systems transparent. Finally, I make normative and descriptive arguments for the moral status of intelligent systems and contribute to regulatory policy regarding such systems.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@phdthesis</span><span class="p">{</span><span class="nl">Theodorou2019Thesis</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Theodorou, Andreas}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{{https://github.com/RecklessCoding/recklesscoding.github.io/raw/master/files/andreasTheodorouThesis.pdf}}</span><span class="p">,</span>
  <span class="na">school</span> <span class="p">=</span> <span class="s">{University of Bath}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{AI Governance Through a Transparency Lens}}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ff7802"> <div style="color:white">Proceedings</div> </abbr> <keyword class="badge rounded w-100" style="background-color:#5dd655"> <div style="color:white">Games AI</div> </keyword> <keyword class="badge rounded w-100">MAS</keyword> </div> <div id="Theodorou2019COG" class="col-sm-8"> <div class="title">The Sustainability Game : AI Technology as an Intervention for Public Understanding of Cooperative Investment</div> <div class="author"> <em>Andreas Theodorou</em>, Bryn Bandt-law, and Joanna J Bryson </div> <div class="periodical"> <em>In IEEE Conference on Games</em>, 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/CIG.2019.8848058" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://researchportal.bath.ac.uk/files/196356314/TheodorouBandtLawBrysonCoG19.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> <div class="badges"> <span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=JEw-BycAAAAJ&amp;citation_for_view=JEw-BycAAAAJ:2osOgNQ5qMEC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-12-4285F4?logo=googlescholar&amp;labelColor=beige" alt="12 Google Scholar citations"> </a> </span> <span class="__dimensions_badge_embed__" data-doi="10.1109/CIG.2019.8848058" data-style="small_rectangle" data-legend="hover-right" data-hide-zero-citations="true" style="margin-bottom: 2px;"></span> <span class="altmetric-embed" data-badge-type="2" data-badge-popover="right" data-hide-no-mentions="true" data-doi="10.1109/CIG.2019.8848058" style="padding-right:0rem"></span> <span> <a href="https://plu.mx/plum/a/?doi=10.1109/CIG.2019.8848058" data-popup="right" data-size="small" class="plumx-plum-print-popup" data-site="plum" data-hide-when-empty="true" rel="external nofollow noopener" target="_blank"> </a> </span> </div> <div class="abstract hidden"> <p>Cooperative behaviour is a fundamental strategy for survival; it positively affects economies, social relationships, and makes larger societal structures possible. People vary, however, in their willingness to engage in cooperative behaviour in a particular context. Here we examine whether AI can be effectively used to to alter individuals’ implicit understanding of cooperative dynamics, and hence increase cooperation and participation in public goods projects. We developed an intervention—the Sustainability Game (SG)—to allow players to experience the consequences of individual investment strategies on a sustainable society. Results show that the intervention significantly increases individuals’ cooperative behaviour in partially anonymised public goods contexts, but enhances competition one-on-one. This indicates our intervention does improve transparency of the systemic consequences of individual cooperative behaviour.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Theodorou2019COG</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Theodorou, Andreas and Bandt-law, Bryn and Bryson, Joanna J}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IEEE Conference on Games}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{The Sustainability Game : AI Technology as an Intervention for Public Understanding of Cooperative Investment}}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/CIG.2019.8848058}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://researchportal.bath.ac.uk/files/196356314/TheodorouBandtLawBrysonCoG19.pdf}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ff7802"> <div style="color:white">Proceedings</div> </abbr> <keyword class="badge rounded w-100" style="background-color:#851868"> <div style="color:white">Governance</div> </keyword> </div> <div id="AlerTubellaEtAl2019IJCAI" class="col-sm-8"> <div class="title">Governance by Glass-Box: Implementing Transparent Moral Bounds for AI Behaviour</div> <div class="author"> Andrea Aler Tubella, <em>Andreas Theodorou</em>, Virginia Dignum, and Frank Dignum </div> <div class="periodical"> <em>In International Joint Conference on Artificial Intellignece (IJCAI)</em>, 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.24963/ijcai.2019/802" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a href="http://arxiv.org/abs/1905.04994" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.ijcai.org/proceedings/2019/0802.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> <div class="badges"> <span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=JEw-BycAAAAJ&amp;citation_for_view=JEw-BycAAAAJ:8k81kl-MbHgC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-64-4285F4?logo=googlescholar&amp;labelColor=beige" alt="64 Google Scholar citations"> </a> </span> <span class="__dimensions_badge_embed__" data-doi="10.24963/ijcai.2019/802" data-style="small_rectangle" data-legend="hover-right" data-hide-zero-citations="true" style="margin-bottom: 2px;"></span> <span class="altmetric-embed" data-badge-type="2" data-badge-popover="right" data-hide-no-mentions="true" data-altmetric-id="67471871" style="padding-right:0rem"></span> <span> <a href="https://plu.mx/plum/a/?doi=10.24963/ijcai.2019/802" data-popup="right" data-size="small" class="plumx-plum-print-popup" data-site="plum" data-hide-when-empty="true" rel="external nofollow noopener" target="_blank"> </a> </span> </div> <div class="abstract hidden"> <p>Artificial Intelligence (AI) applications are being used to predict and assess behaviour in multiple domains, such as criminal justice and consumer finance, which directly affect human well-being. However, if AI is to improve people’s lives, then people must be able to trust AI, which means being able to understand what the system is doing and why. Even though transparency is often seen as the requirement in this case, realistically it might not always be possible or desirable, whereas the need to ensure that the system operates within set moral bounds remains. In this paper, we present an approach to evaluate the moral bounds of an AI system based on the monitoring of its inputs and outputs. We place a "glass box" around the system by mapping moral values into explicit verifiable norms that constrain inputs and outputs, in such a way that if these remain within the box we can guarantee that the system adheres to the value. The focus on inputs and outputs allows for the verification and comparison of vastly different intelligent systems; from deep neural networks to agent-based systems. The explicit transformation of abstract moral values into concrete norms brings great benefits in terms of explainability; stakeholders know exactly how the system is interpreting and employing relevant abstract moral human values and calibrate their trust accordingly. Moreover, by operating at a higher level we can check the compliance of the system with different interpretations of the same value. These advantages will have an impact on the well-being of AI systems users at large, building their trust and providing them with concrete knowledge on how systems adhere to moral values.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">AlerTubellaEtAl2019IJCAI</span><span class="p">,</span>
  <span class="na">archiveprefix</span> <span class="p">=</span> <span class="s">{arXiv}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{{Aler Tubella}, Andrea and Theodorou, Andreas and Dignum, Virginia and Dignum, Frank}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{International Joint Conference on Artificial Intellignece (IJCAI)}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Governance by Glass-Box: Implementing Transparent Moral Bounds for AI Behaviour}}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.ijcai.org/proceedings/2019/0802.pdf}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.24963/ijcai.2019/802}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ff7802"> <div style="color:white">Proceedings</div> </abbr> <keyword class="badge rounded w-100" style="background-color:#851868"> <div style="color:white">H-AI Int.</div> </keyword> <keyword class="badge rounded w-100" style="background-color:#154e54"> <div style="color:white">Transparency</div> </keyword> </div> <div id="WilsonTheodorou2019" class="col-sm-8"> <div class="title">Slam the Brakes: Perceptions of Moral Decisions in Driving Dilemmas</div> <div class="author"> Holly Wilson and <em>Andreas Theodorou</em> </div> <div class="periodical"> <em>In IJCAI 2019 Workshop on AISafety</em>, 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="http://ceur-ws.org/Vol-2419/paper_14.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> <div class="badges"> <span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=JEw-BycAAAAJ&amp;citation_for_view=JEw-BycAAAAJ:MXK_kJrjxJIC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-16-4285F4?logo=googlescholar&amp;labelColor=beige" alt="16 Google Scholar citations"> </a> </span> <span> <a href="https://plu.mx/plum/a/?doi=" data-popup="right" data-size="small" class="plumx-plum-print-popup" data-site="plum" data-hide-when-empty="true" rel="external nofollow noopener" target="_blank"> </a> </span> </div> <div class="abstract hidden"> <p>Artificially intelligent agents are increasingly used for morally-salient decisions of high societal impact. Yet, the decision-making algorithms of such agents are rarely transparent. Further, our perception of, and response to, morally-salient decisions may depend on agent type; artificial or natural (human). We developed a Virtual Reality (VR) simulation involving an autonomous vehicle to investigate our perceptions of a morally-salient decision; first moderated by agent type, and second, by an implementation of transparency. Participants in our user study took the role of a passenger in an autonomous vehicle (AV) which makes a moral choice: crash into one of two human-looking Non-Playable Characters (NPC). Experimental subjects were exposed to one of three conditions: (1) participants were led to believe that the car was controlled by a human, (2) the artificial nature of AV was made explicitly clear in the pre-study briefing, but its decisionmaking system was kept opaque, and (3) a transparent AV that reported back the characteristics of the NPCs that influenced its decision-making process. In this paper, we discuss our results, including the distress expressed by our participants at exposing them to a system that makes decisions based on socio-demographic attributes, and their implications.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">WilsonTheodorou2019</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Macao, China}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wilson, Holly and Theodorou, Andreas}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IJCAI 2019 Workshop on AISafety}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Slam the Brakes: Perceptions of Moral Decisions in Driving Dilemmas}}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{{http://ceur-ws.org/Vol-2419/paper_14.pdf}}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ff7802"> <div style="color:white">Proceedings</div> </abbr> <keyword class="badge rounded w-100" style="background-color:#851868"> <div style="color:white">H-AI Int.</div> </keyword> <keyword class="badge rounded w-100" style="background-color:#154e54"> <div style="color:white">Transparency</div> </keyword> </div> <div id="RotsidisEtAl2019IUI" class="col-sm-8"> <div class="title">Robots that make sense: Transparent intelligence through augmented reality</div> <div class="author"> Alexandros Rotsidis, <em>Andreas Theodorou</em>, and Robert H. Wortham </div> <div class="periodical"> <em>In IUI’19 Workshop on Intelligent User Interfaces for Algorithmic Transparency in Emerging Technologies</em>, 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ceur-ws.org/Vol-2327/IUI19WS-IUIATEC-3.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> <div class="badges"> <span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=JEw-BycAAAAJ&amp;citation_for_view=JEw-BycAAAAJ:e5wmG9Sq2KIC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-3-4285F4?logo=googlescholar&amp;labelColor=beige" alt="3 Google Scholar citations"> </a> </span> <span> <a href="https://plu.mx/plum/a/?doi=" data-popup="right" data-size="small" class="plumx-plum-print-popup" data-site="plum" data-hide-when-empty="true" rel="external nofollow noopener" target="_blank"> </a> </span> </div> <div class="abstract hidden"> <p>Autonomous robots can be difficult to understand by their develop-ers, let alone by end users. Yet, as they become increasingly integralparts of our societies, the need for affordable easy to use tools toprovide transparency grows. The rise of the smartphone and theimprovements in mobile computing performance have graduallyallowed Augmented Reality (AR) to become more mobile and afford-able. In this paper we review relevant robot systems architectureand propose a new software tool to provide robot transparencythrough the use of AR technology. Our new tool, ABOD3-AR pro-vides real-time graphical visualisation and debugging of a robot’sgoals and priorities as a means for both designers and end usersto gain a better mental model of the internal state and decisionmaking processes taking place within a robot. We also report onour on-going research programme and planned studies to furtherunderstand the effects of transparency to naive users and experts.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">RotsidisEtAl2019IUI</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Robots that make sense: Transparent intelligence through augmented reality}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{2327}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Los Angeles, CA USA}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Rotsidis, Alexandros and Theodorou, Andreas and Wortham, Robert H.}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IUI'19 Workshop on Intelligent User Interfaces for Algorithmic Transparency in Emerging Technologies}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ceur-ws.org/Vol-2327/IUI19WS-IUIATEC-3.pdf}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2017</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#af0000"> <div style="color:white">Journal</div> </abbr> <keyword class="badge rounded w-100" style="background-color:#851868"> <div style="color:white">Governance</div> </keyword> <keyword class="badge rounded w-100" style="background-color:#154e54"> <div style="color:white">Transparency</div> </keyword> </div> <div id="Theodorou2017ConnectionScience" class="col-sm-8"> <div class="title">Designing and implementing transparency for real time inspection of autonomous robots</div> <div class="author"> <em>Andreas Theodorou</em>, Robert H. Wortham, and Joanna J. Bryson </div> <div class="periodical"> <em>Connection Science</em>, 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1080/09540091.2017.1310182" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://researchportal.bath.ac.uk/files/154473870/TheodorouDesigningAndImplementingTransparency.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> <div class="badges"> <span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=JEw-BycAAAAJ&amp;citation_for_view=JEw-BycAAAAJ:TFP_iSt0sucC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-161-4285F4?logo=googlescholar&amp;labelColor=beige" alt="161 Google Scholar citations"> </a> </span> <span class="__dimensions_badge_embed__" data-doi="10.1080/09540091.2017.1310182" data-style="small_rectangle" data-legend="hover-right" data-hide-zero-citations="true" style="margin-bottom: 2px;"></span> <span class="altmetric-embed" data-badge-type="2" data-badge-popover="right" data-hide-no-mentions="true" data-altmetric-id="20700963" style="padding-right:0rem"></span> <span> <a href="https://plu.mx/plum/a/?doi=10.1080/09540091.2017.1310182" data-popup="right" data-size="small" class="plumx-plum-print-popup" data-site="plum" data-hide-when-empty="true" rel="external nofollow noopener" target="_blank"> </a> </span> </div> <div class="abstract hidden"> <p>The EPSRC’s Principles of Robotics advises the implementation of transparency in robotic systems, however research related to AI transparency is in its infancy. This paper introduces the reader of the importance of having transparent inspection of intelligent agents and provides guidance for good practice when developing such agents. By considering and expanding upon other prominent definitions found in literature, we provide a robust definition of transparency as a mechanism to expose the decision-making of a robot. The paper continues by addressing potential design decisions developers need to consider when designing and developing transparent systems. Finally, we describe our new interactive intelligence editor, designed to visualise, develop and debug real-time intelligence.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Theodorou2017ConnectionScience</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Theodorou, Andreas and Wortham, Robert H. and Bryson, Joanna J.}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1080/09540091.2017.1310182}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{13600494}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Connection Science}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{3}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{230--241}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Designing and implementing transparency for real time inspection of autonomous robots}}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://researchportal.bath.ac.uk/files/154473870/TheodorouDesigningAndImplementingTransparency.pdf}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{29}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#af0000"> <div style="color:white">Journal</div> </abbr> <keyword class="badge rounded w-100" style="background-color:#851868"> <div style="color:white">Governance</div> </keyword> <keyword class="badge rounded w-100" style="background-color:#154e54"> <div style="color:white">Transparency</div> </keyword> </div> <div id="Wortham2017ConnScience" class="col-sm-8"> <div class="title">Robot transparency, trust and utility</div> <div class="author"> Robert H. Wortham and <em>Andreas Theodorou</em> </div> <div class="periodical"> <em>Connection Science</em>, 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1080/09540091.2017.1313816" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://researchportal.bath.ac.uk/files/154037267/transparency.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1080/09540091.2017.1313816" data-style="small_rectangle" data-legend="hover-right" data-hide-zero-citations="true" style="margin-bottom: 2px;"></span> <span class="altmetric-embed" data-badge-type="2" data-badge-popover="right" data-hide-no-mentions="true" data-altmetric-id="20851124" style="padding-right:0rem"></span> <span> <a href="https://plu.mx/plum/a/?doi=10.1080/09540091.2017.1313816" data-popup="right" data-size="small" class="plumx-plum-print-popup" data-site="plum" data-hide-when-empty="true" rel="external nofollow noopener" target="_blank"> </a> </span> </div> <div class="abstract hidden"> <p>As robot reasoning becomes more complex, debugging becomes increasingly hard based solely on observable behaviour, even for robot designers and technical specialists. Similarly, non-specialist users find it hard to create useful mental models of robot reasoning solely from observed behaviour. The EPSRC Principles of Robotics mandate that our artefacts should be transparent, but what does this mean in practice, and how does transparency affect both trust and utility? We investigate this relationship in the literature and find it to be complex, particularly in non industrial environments where transparency may have a wider range of effects on trust and utility depending on the application and purpose of the robot. We outline our programme of research to support our assertion that it is nevertheless possible to create transparent agents that are emotion-ally engaging despite having a transparent machine nature.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Wortham2017ConnScience</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wortham, Robert H. and Theodorou, Andreas}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1080/09540091.2017.1313816}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{13600494}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Connection Science}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{3}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{242--248}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Robot transparency, trust and utility}}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://researchportal.bath.ac.uk/files/154037267/transparency.pdf}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{29}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
  <span class="na">google_scholar</span> <span class="p">=</span> <span class="s">{d1gkVwhDpl0C}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ff7802"> <div style="color:white">Proceedings</div> </abbr> <keyword class="badge rounded w-100" style="background-color:#851868"> <div style="color:white">H-AI Int.</div> </keyword> <keyword class="badge rounded w-100" style="background-color:#154e54"> <div style="color:white">Transparency</div> </keyword> </div> <div id="Wortham2017ROMAN" class="col-sm-8"> <div class="title">Improving robot transparency: Real-Time visualisation of robot AI substantially improves understanding in naive observers</div> <div class="author"> Robert H. Wortham, <em>Andreas Theodorou</em>, and Joanna J. Bryson </div> <div class="periodical"> <em>In RO-MAN 2017 - 26th IEEE International Symposium on Robot and Human Interactive Communication</em>, 2017 </div> <div class="periodical"> </div> <div class="links"> <a href="https://doi.org/10.1109/ROMAN.2017.8172491" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://researchportal.bath.ac.uk/files/155724003/robot_transparency_experiment.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> <div class="badges"> <span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=JEw-BycAAAAJ&amp;citation_for_view=JEw-BycAAAAJ:Tyk-4Ss8FVUC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-65-4285F4?logo=googlescholar&amp;labelColor=beige" alt="65 Google Scholar citations"> </a> </span> <span class="__dimensions_badge_embed__" data-doi="10.1109/ROMAN.2017.8172491" data-style="small_rectangle" data-legend="hover-right" data-hide-zero-citations="true" style="margin-bottom: 2px;"></span> <span class="altmetric-embed" data-badge-type="2" data-badge-popover="right" data-hide-no-mentions="true" data-doi="10.1109/ROMAN.2017.8172491" style="padding-right:0rem"></span> <span> <a href="https://plu.mx/plum/a/?doi=10.1109/ROMAN.2017.8172491" data-popup="right" data-size="small" class="plumx-plum-print-popup" data-site="plum" data-hide-when-empty="true" rel="external nofollow noopener" target="_blank"> </a> </span> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Wortham2017ROMAN</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wortham, Robert H. and Theodorou, Andreas and Bryson, Joanna J.}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{RO-MAN 2017 - 26th IEEE International Symposium on Robot and Human Interactive Communication}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ROMAN.2017.8172491}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9781538635186}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1528-1132 0009-921X}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1424--1431}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Improving robot transparency: Real-Time visualisation of robot AI substantially improves understanding in naive observers}}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://researchportal.bath.ac.uk/files/155724003/robot{\_}transparency{\_}experiment.pdf}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{2017-Janua}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ff7802"> <div style="color:white">Proceedings</div> </abbr> <keyword class="badge rounded w-100" style="background-color:#851868"> <div style="color:white">H-AI Int.</div> </keyword> <keyword class="badge rounded w-100" style="background-color:#154e54"> <div style="color:white">Transparency</div> </keyword> </div> <div id="WorthamEtAl2017TAROS" class="col-sm-8"> <div class="title">Robot transparency: Improving understanding of intelligent behaviour for designers and users</div> <div class="author"> Robert H. Wortham, <em>Andreas Theodorou</em>, and Joanna J. Bryson </div> <div class="periodical"> <em>Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)</em>, 2017 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1007/978-3-319-64107-2_22" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="badges"> <span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=JEw-BycAAAAJ&amp;citation_for_view=JEw-BycAAAAJ:zYLM7Y9cAGgC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-53-4285F4?logo=googlescholar&amp;labelColor=beige" alt="53 Google Scholar citations"> </a> </span> <span class="__dimensions_badge_embed__" data-doi="10.1007/978-3-319-64107-2_22" data-style="small_rectangle" data-legend="hover-right" data-hide-zero-citations="true" style="margin-bottom: 2px;"></span> <span class="altmetric-embed" data-badge-type="2" data-badge-popover="right" data-hide-no-mentions="true" data-altmetric-id="22305660" style="padding-right:0rem"></span> <span> <a href="https://plu.mx/plum/a/?doi=10.1007/978-3-319-64107-2_22" data-popup="right" data-size="small" class="plumx-plum-print-popup" data-site="plum" data-hide-when-empty="true" rel="external nofollow noopener" target="_blank"> </a> </span> </div> <div class="abstract hidden"> <p>Autonomous robots can be difficult to design and understand. Designers have difficulty decoding the behaviour of their own robots simply by observing them. Naive users of robots similarly have diculty decoding robot behaviour simply through observation. In this paper we review relevant robot systems architecture, design and transparency literature, and report on a programme of research to investigate practical approaches to improve robot transparency. We report on the investigation of real-time graphical and vocalised outputs as a means for both designers and end users to gain a better mental model of the internal state and decision making processes taking place within a robot. This approach, combined with a graphical approach to behaviour design, o ers improved transparency for robot designers. We also report on studies of users’ understanding, where significant improvement has been achieved using both graphical and vocalisation transparency approaches.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">WorthamEtAl2017TAROS</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wortham, Robert H. and Theodorou, Andreas and Bryson, Joanna J.}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1007/978-3-319-64107-2_22}</span><span class="p">,</span>
  <span class="na">isbn</span> <span class="p">=</span> <span class="s">{9783319641065}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{16113349}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{274--289}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Robot transparency: Improving understanding of intelligent behaviour for designers and users}}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{10454}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2017}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2016</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ff7802"> <div style="color:white">Proceedings</div> </abbr> <keyword class="badge rounded w-100" style="background-color:#851868"> <div style="color:white">Governance</div> </keyword> <keyword class="badge rounded w-100" style="background-color:#154e54"> <div style="color:white">Transparency</div> </keyword> </div> <div id="Theodorou2016EUCog" class="col-sm-8"> <div class="title">ABOD3: A graphical visualisation and real-time debugging tool for bod agents</div> <div class="author"> <em>Andreas Theodorou</em> </div> <div class="periodical"> <em>In Proceedings of the EUCognition Meeeting on Cognitive Robot Architectures</em>, 2016 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ceur-ws.org/Vol-1855/EUCognition_2016_Part19.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> <div class="badges"> <span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=JEw-BycAAAAJ&amp;citation_for_view=JEw-BycAAAAJ:2osOgNQ5qMEC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-12-4285F4?logo=googlescholar&amp;labelColor=beige" alt="12 Google Scholar citations"> </a> </span> <span> <a href="https://plu.mx/plum/a/?doi=" data-popup="right" data-size="small" class="plumx-plum-print-popup" data-site="plum" data-hide-when-empty="true" rel="external nofollow noopener" target="_blank"> </a> </span> </div> <div class="abstract hidden"> <p>Current software for AI development requires the use of programming languages to develop intelligent agents. This can be disadvantageous for AI designers, as their work needs to be debugged and treated as a generic piece of software code. Moreover, such approaches are designed for experts; often requiring a steep initial learning curve, as they are tailored for programmers. This can be also disadvantageous for implementing transparency to agents, an important ethical consideration [1], [2], as additional work is needed to expose and represent information to end users. We are working towards the development of a new editor, ABOD3. It allows the graphical visualisation of Behaviour Oriented Design based plans [3], including its two major derivatives: Parallel-rooted, Ordered Slip-stack Hierarchical (POSH) and Instinct [4]. The new editor is designed to allow not only the development of reactive plans, but also to debug such plans in real time to reduce the time required to develop an agent. This allows the development and testing of plans from a same application.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Theodorou2016EUCog</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Theodorou, Andreas}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the EUCognition Meeeting on Cognitive Robot Architectures}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{16130073}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{60--61}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{ABOD3: A graphical visualisation and real-time debugging tool for bod agents}}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{1855}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2016}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://ceur-ws.org/Vol-1855/EUCognition_2016_Part19.pdf}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#ff7802"> <div style="color:white">Proceedings</div> </abbr> <keyword class="badge rounded w-100" style="background-color:#851868"> <div style="color:white">H-AI Int.</div> </keyword> <keyword class="badge rounded w-100" style="background-color:#154e54"> <div style="color:white">Transparency</div> </keyword> </div> <div id="WorthamEtAl2016IJCAI" class="col-sm-8"> <div class="title">What Does the Robot Think? Transparency as a Fundamental Design Requirement for Intelligent Systems</div> <div class="author"> Robert H. Wortham, <em>Andreas Theodorou</em>, and Joanna J. Bryson </div> <div class="periodical"> <em>In IJCAI 2016 Ethics for Artificial Intelligence Workshop</em>, 2016 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://researchportal.bath.ac.uk/files/145736287/WorthamTheodorouBryson_EFAI16.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Paper</a> </div> <div class="badges"> <span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=JEw-BycAAAAJ&amp;citation_for_view=JEw-BycAAAAJ:ZeXyd9-uunAC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-101-4285F4?logo=googlescholar&amp;labelColor=beige" alt="101 Google Scholar citations"> </a> </span> <span> <a href="https://plu.mx/plum/a/?doi=" data-popup="right" data-size="small" class="plumx-plum-print-popup" data-site="plum" data-hide-when-empty="true" rel="external nofollow noopener" target="_blank"> </a> </span> </div> <div class="abstract hidden"> <p>Deciphering the behaviour of intelligent others is a fundamental characteristic of our own intelligence. As we interact with complex intelligent artefacts, humans inevitably construct mental models to understand and predict their behaviour. If these models are incorrect or inadequate, we run the risk of self deception or even harm. This paper reports progress on a programme of work investigating approaches for implementing robot transparency, and the effects of these approaches on utility, trust and the perception of agency. Preliminary findings indicate that building transparency into robot action selection can help users build a more accurate understanding of the robot.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">WorthamEtAl2016IJCAI</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wortham, Robert H. and Theodorou, Andreas and Bryson, Joanna J.}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{IJCAI 2016 Ethics for Artificial Intelligence Workshop}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{What Does the Robot Think? Transparency as a Fundamental Design Requirement for Intelligent Systems}}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://researchportal.bath.ac.uk/files/145736287/WorthamTheodorouBryson_EFAI16.pdf}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2016}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{New York, NY, US}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="sticky-bottom mt-5" role="contentinfo"> <div class="container"> © Copyright 2026 Andreas Theodorou. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?v=a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript" src="//cdn.plu.mx/widget-popup.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> </body> </html>